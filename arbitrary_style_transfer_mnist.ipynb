{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arbitrary_style_transfer_mnist_svhn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LqaLiQQysc"
      },
      "source": [
        "**other_utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4sHmLbMPtnf"
      },
      "source": [
        "\"\"\"General utilities for displaying and loading data, RGB to gray\r\n",
        "function, and testing source/target generators\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import math\r\n",
        "\r\n",
        "def rgb2gray(rgb):\r\n",
        "    \"\"\"Convert from color image (RGB) to grayscale\r\n",
        "       Reference: opencv.org\r\n",
        "       Formula: grayscale = 0.299*red + 0.587*green + 0.114*blue\r\n",
        "    \"\"\"\r\n",
        "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\r\n",
        "\r\n",
        "\r\n",
        "def display_images(imgs,\r\n",
        "                   filename,\r\n",
        "                   title='',\r\n",
        "                   imgs_dir=None,\r\n",
        "                   show=False):\r\n",
        "    \"\"\"Display images in an nxn grid\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    imgs (tensor): array of images\r\n",
        "    filename (string): filename to save the displayed image\r\n",
        "    title (string): title on the displayed image\r\n",
        "    imgs_dir (string): directory where to save the files\r\n",
        "    show (bool): whether to display the image or not \r\n",
        "          (False during training, True during testing)\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    rows = imgs.shape[1]\r\n",
        "    cols = imgs.shape[2]\r\n",
        "    channels = imgs.shape[3]\r\n",
        "    side = int(math.sqrt(imgs.shape[0]))\r\n",
        "    assert int(side * side) == imgs.shape[0]\r\n",
        "\r\n",
        "    # create saved_images folder\r\n",
        "    if imgs_dir is None:\r\n",
        "        imgs_dir = 'saved_images'\r\n",
        "    save_dir = os.path.join(os.getcwd(), imgs_dir)\r\n",
        "    if not os.path.isdir(save_dir):\r\n",
        "        os.makedirs(save_dir)\r\n",
        "    filename = os.path.join(imgs_dir, filename)\r\n",
        "    # rows, cols, channels = img_shape\r\n",
        "    if channels==1:\r\n",
        "        imgs = imgs.reshape((side, side, rows, cols))\r\n",
        "    else:\r\n",
        "        imgs = imgs.reshape((side, side, rows, cols, channels))\r\n",
        "    imgs = np.vstack([np.hstack(i) for i in imgs])\r\n",
        "    plt.figure()\r\n",
        "    plt.axis('off')\r\n",
        "    plt.title(title)\r\n",
        "    if channels==1:\r\n",
        "        plt.imshow(imgs, interpolation='none', cmap='gray')\r\n",
        "    else:\r\n",
        "        plt.imshow(imgs, interpolation='none')\r\n",
        "    plt.savefig(filename)\r\n",
        "    if show:\r\n",
        "        plt.show()\r\n",
        "    \r\n",
        "    plt.close('all')\r\n",
        "\r\n",
        "\r\n",
        "def test_generator_utility(generators,\r\n",
        "                   test_data,\r\n",
        "                   step,\r\n",
        "                   titles,\r\n",
        "                   dirs,\r\n",
        "                   todisplay=100,\r\n",
        "                   show=False):\r\n",
        "    \"\"\"Test the generator models\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    generators (tuple): source and target generators\r\n",
        "    test_data (tuple): source and target test data\r\n",
        "    step (int): step number during training (0 during testing)\r\n",
        "    titles (tuple): titles on the displayed image\r\n",
        "    dirs (tuple): folders to save the outputs of testings\r\n",
        "    todisplay (int): number of images to display (must be\r\n",
        "        perfect square)\r\n",
        "    show (bool): whether to display the image or not \r\n",
        "          (False during training, True during testing)\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "\r\n",
        "    # predict the output from test data\r\n",
        "    g_source, g_target = generators\r\n",
        "    test_source_data, test_target_data = test_data\r\n",
        "    t1, t2, t3, t4 = titles\r\n",
        "    title_pred_source = t1\r\n",
        "    title_pred_target = t2\r\n",
        "    title_reco_source = t3\r\n",
        "    title_reco_target = t4\r\n",
        "    dir_pred_source, dir_pred_target = dirs\r\n",
        "\r\n",
        "    pred_target_data = g_target.predict(test_source_data)\r\n",
        "    pred_source_data = g_source.predict(test_target_data)\r\n",
        "    reco_source_data = g_source.predict(pred_target_data)\r\n",
        "    reco_target_data = g_target.predict(pred_source_data)\r\n",
        "\r\n",
        "    # display the 1st todisplay images\r\n",
        "    imgs = pred_target_data[:todisplay]\r\n",
        "    filename = '%06d.png' % step\r\n",
        "    step = \" Step: {:,}\".format(step)\r\n",
        "    title = title_pred_target + step\r\n",
        "    display_images(imgs,\r\n",
        "                   filename=filename,\r\n",
        "                   imgs_dir=dir_pred_target,\r\n",
        "                   title=title,\r\n",
        "                   show=show)\r\n",
        "\r\n",
        "    imgs = pred_source_data[:todisplay]\r\n",
        "    title = title_pred_source\r\n",
        "    display_images(imgs,\r\n",
        "                   filename=filename,\r\n",
        "                   imgs_dir=dir_pred_source,\r\n",
        "                   title=title,\r\n",
        "                   show=show)\r\n",
        "\r\n",
        "    imgs = reco_source_data[:todisplay]\r\n",
        "    title = title_reco_source\r\n",
        "    filename = \"reconstructed_source.png\"\r\n",
        "    display_images(imgs,\r\n",
        "                   filename=filename,\r\n",
        "                   imgs_dir=dir_pred_source,\r\n",
        "                   title=title,\r\n",
        "                   show=show)\r\n",
        "\r\n",
        "    imgs = reco_target_data[:todisplay]\r\n",
        "    title = title_reco_target\r\n",
        "    filename = \"reconstructed_target.png\"\r\n",
        "    display_images(imgs,\r\n",
        "                   filename=filename,\r\n",
        "                   imgs_dir=dir_pred_target,\r\n",
        "                   title=title,\r\n",
        "                   show=show)\r\n",
        "\r\n",
        "\r\n",
        "def load_data_utility(data, titles, filenames, todisplay=100):\r\n",
        "    \"\"\"Generic loaded data transformation\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    data (tuple): source, target, test source, test target data\r\n",
        "    titles (tuple): titles of the test and source images to display\r\n",
        "    filenames (tuple): filenames of the test and source images to\r\n",
        "       display\r\n",
        "    todisplay (int): number of images to display (must be\r\n",
        "        perfect square)\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    source_data, target_data, test_source_data, test_target_data = data\r\n",
        "    test_source_filename, test_target_filename = filenames\r\n",
        "    test_source_title, test_target_title = titles\r\n",
        "\r\n",
        "    # display test target images\r\n",
        "    imgs = test_target_data[:todisplay]\r\n",
        "    display_images(imgs,\r\n",
        "                   filename=test_target_filename,\r\n",
        "                   title=test_target_title)\r\n",
        "\r\n",
        "    # display test source images\r\n",
        "    imgs = test_source_data[:todisplay]\r\n",
        "    display_images(imgs,\r\n",
        "                   filename=test_source_filename,\r\n",
        "                   title=test_source_title)\r\n",
        "\r\n",
        "    # normalize images\r\n",
        "    target_data = target_data.astype('float32')  / 255\r\n",
        "    test_target_data = test_target_data.astype('float32') / 255\r\n",
        "\r\n",
        "    source_data = source_data.astype('float32')  / 255\r\n",
        "    test_source_data = test_source_data.astype('float32') / 255\r\n",
        "\r\n",
        "    # source data, target data, test_source data\r\n",
        "    data = (source_data, target_data, test_source_data, test_target_data)\r\n",
        "\r\n",
        "    rows = source_data.shape[1]\r\n",
        "    cols = source_data.shape[2]\r\n",
        "    channels = source_data.shape[3]\r\n",
        "    source_shape = (rows, cols, channels)\r\n",
        "\r\n",
        "    rows = target_data.shape[1]\r\n",
        "    cols = target_data.shape[2]\r\n",
        "    channels = target_data.shape[3]\r\n",
        "    target_shape = (rows, cols, channels)\r\n",
        "\r\n",
        "    shapes = (source_shape, target_shape)\r\n",
        "    \r\n",
        "    return data, shapes\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CEr6hzUQ6q9"
      },
      "source": [
        "**mnist_svhn_utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzShPw1NPpI2"
      },
      "source": [
        "\"\"\"Utilities for loading MNIST and SVHN\r\n",
        "\r\n",
        "Street View House Number (SVHN) dataset:\r\n",
        "http://ufldl.stanford.edu/housenumbers/\r\n",
        "\r\n",
        "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, \r\n",
        "Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with \r\n",
        "Unsupervised Feature Learning NIPS Workshop on Deep Learning \r\n",
        "and Unsupervised Feature Learning 2011. (PDF)\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "from tensorflow.keras.datasets import mnist\r\n",
        "from tensorflow.keras.utils import get_file\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from scipy import io\r\n",
        "#import other_utils\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "def get_datadir():\r\n",
        "    cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\r\n",
        "    cache_subdir = 'datasets'\r\n",
        "    datadir_base = os.path.expanduser(cache_dir)\r\n",
        "    if not os.access(datadir_base, os.W_OK):\r\n",
        "        datadir_base = os.path.join('/tmp', '.keras')\r\n",
        "\r\n",
        "    datadir = os.path.join(datadir_base, cache_subdir)\r\n",
        "    if not os.path.exists(datadir):\r\n",
        "        os.makedirs(datadir)\r\n",
        "\r\n",
        "    return datadir\r\n",
        "\r\n",
        "\r\n",
        "def mnist_svhn_load_data():\r\n",
        "    # load mnist data\r\n",
        "    (source_data, _), (test_source_data, _) = mnist.load_data()\r\n",
        "\r\n",
        "    # pad with zeros 28x28 MNIST image to become 32x32\r\n",
        "    # svhn is 32x32\r\n",
        "    source_data = np.pad(source_data,\r\n",
        "                         ((0,0), (2,2), (2,2)),\r\n",
        "                         'constant',\r\n",
        "                         constant_values=0)\r\n",
        "    test_source_data = np.pad(test_source_data,\r\n",
        "                              ((0,0), (2,2), (2,2)),\r\n",
        "                              'constant',\r\n",
        "                              constant_values=0)\r\n",
        "    # input image dimensions\r\n",
        "    # we assume data format \"channels_last\"\r\n",
        "    rows = source_data.shape[1]\r\n",
        "    cols = source_data.shape[2]\r\n",
        "    channels = 1\r\n",
        "\r\n",
        "    # reshape images to row x col x channels\r\n",
        "    # for CNN output/validation\r\n",
        "    size = source_data.shape[0]\r\n",
        "    source_data = source_data.reshape(size,\r\n",
        "                                      rows,\r\n",
        "                                      cols,\r\n",
        "                                      channels)\r\n",
        "    size = test_source_data.shape[0]\r\n",
        "    test_source_data = test_source_data.reshape(size,\r\n",
        "                                                rows,\r\n",
        "                                                cols,\r\n",
        "                                                channels)\r\n",
        "\r\n",
        "    # load SVHN data\r\n",
        "    datadir = get_datadir()\r\n",
        "    get_file('train_32x32.mat',\r\n",
        "             origin='http://ufldl.stanford.edu/housenumbers/train_32x32.mat')\r\n",
        "    get_file('test_32x32.mat',\r\n",
        "             'http://ufldl.stanford.edu/housenumbers/test_32x32.mat')\r\n",
        "    path = os.path.join(datadir, 'train_32x32.mat')\r\n",
        "    target_data = loadmat(path)\r\n",
        "    path = os.path.join(datadir, 'test_32x32.mat')\r\n",
        "    test_target_data = loadmat(path)\r\n",
        "\r\n",
        "    # source data, target data, test_source data\r\n",
        "    data = (source_data, target_data, test_source_data, test_target_data)\r\n",
        "    filenames = ('mnist_test_source.png', 'svhn_test_target.png')\r\n",
        "    titles = ('MNIST test source images', 'SVHN test target images')\r\n",
        "    \r\n",
        "    return load_data_utility(data, titles, filenames)\r\n",
        "\r\n",
        "\r\n",
        "def loadmat(filename):\r\n",
        "    # load SVHN dataset\r\n",
        "    mat = io.loadmat(filename)\r\n",
        "    # the key to image data is 'X', the image label key is 'y'\r\n",
        "    data = mat['X']\r\n",
        "    rows =data.shape[0]\r\n",
        "    cols = data.shape[1]\r\n",
        "    channels = data.shape[2]\r\n",
        "    # in matlab data, the image index is the last index\r\n",
        "    # in keras, the image index is the first index so\r\n",
        "    # perform transpose for the last index\r\n",
        "    data = np.transpose(data, (3, 0, 1, 2))\r\n",
        "    return data\r\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w4fd2g4kiWv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2R7MNC0kioX"
      },
      "source": [
        "import keras\r\n",
        "\r\n",
        "class AdaptiveInstanceNorm(keras.layers.Layer):\r\n",
        "    def __init__(self, epsilon=1e-3):\r\n",
        "        super(AdaptiveInstanceNorm, self).__init__()\r\n",
        "        self.epsilon = epsilon\r\n",
        "\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        x, style = inputs\r\n",
        "        axis = [1, 2]\r\n",
        "        x_mean = K.mean(x, axis=axis, keepdims=True)\r\n",
        "        x_std = K.std(x, axis=axis, keepdims=True)\r\n",
        "\r\n",
        "        style_mean = K.mean(style, axis=axis, keepdims=True)\r\n",
        "        style_std = K.std(style, axis=axis, keepdims=True)\r\n",
        "\r\n",
        "        norm = (x - x_mean) * (1 / (x_std + self.epsilon))\r\n",
        "\r\n",
        "        return norm * (style_std + self.epsilon) + style_mean\r\n",
        "\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        return input_shape[0]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyvk4tOcRBs9"
      },
      "source": [
        "**cyclegan-7.1.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO29eBGhKLbc"
      },
      "source": [
        "\"\"\"Builds and trains a CycleGAN\r\n",
        "\r\n",
        "CycleGAN is a cross-domain GAN. Like other GANs, it can be trained\r\n",
        "in unsupervised manner.\r\n",
        "\r\n",
        "CycleGAN is made of two generators (G & F) and two discriminators.\r\n",
        "Each generator is a U-Network. The discriminator is a \r\n",
        "typical decoder network with the option to use PatchGAN structure.\r\n",
        "\r\n",
        "There are 2 datasets: x = source, y = target. \r\n",
        "The forward-cycle solves x'= F(y') = F(G(x)) where y' is \r\n",
        "the predicted output in y-domain and x' is the reconstructed input.\r\n",
        "The target discriminator determines if y' is fake/real. \r\n",
        "The objective of the forward-cycle generator G is to learn \r\n",
        "how to trick the target discriminator into believing that y'\r\n",
        "is real.\r\n",
        "\r\n",
        "The backward-cycle improves the performance of CycleGAN by doing \r\n",
        "the opposite of forward cycle. It learns how to solve\r\n",
        "y' = G(x') = G(F(y)) where x' is the predicted output in the\r\n",
        "x-domain. The source discriminator determines if x' is fake/real.\r\n",
        "The objective of the backward-cycle generator F is to learn \r\n",
        "how to trick the target discriminator into believing that x' \r\n",
        "is real.\r\n",
        "\r\n",
        "References:\r\n",
        "[1]Zhu, Jun-Yan, et al. \"Unpaired Image-to-Image Translation Using\r\n",
        "Cycle-Consistent Adversarial Networks.\" 2017 IEEE International\r\n",
        "Conference on Computer Vision (ICCV). IEEE, 2017.\r\n",
        "\r\n",
        "[2]Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"U-net:\r\n",
        "Convolutional networks for biomedical image segmentation.\"\r\n",
        "International Conference on Medical image computing and\r\n",
        "computer-assisted intervention. Springer, Cham, 2015.\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\r\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\r\n",
        "from tensorflow.keras.layers import Conv2DTranspose\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import concatenate\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "# from keras_contrib.layers.normalization import InstanceNormalization\r\n",
        "# from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\r\n",
        "# install: pip install tensorflow-addons\r\n",
        "from tensorflow_addons.layers import InstanceNormalization\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import argparse\r\n",
        "#import cifar10_utils\r\n",
        "#import mnist_svhn_utils\r\n",
        "#import other_utils\r\n",
        "import datetime\r\n",
        "\r\n",
        "\r\n",
        "def encoder_layer(inputs,\r\n",
        "                  filters=16,\r\n",
        "                  kernel_size=3,\r\n",
        "                  strides=2,\r\n",
        "                  activation='relu',\r\n",
        "                  instance_norm=True):\r\n",
        "    \"\"\"Builds a generic encoder layer made of Conv2D-IN-LeakyReLU\r\n",
        "    IN is optional, LeakyReLU may be replaced by ReLU\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    conv = Conv2D(filters=filters,\r\n",
        "                  kernel_size=kernel_size,\r\n",
        "                  strides=strides,\r\n",
        "                  padding='same')\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if instance_norm:\r\n",
        "        x = InstanceNormalization()(x)\r\n",
        "    if activation == 'relu':\r\n",
        "        x = Activation('relu')(x)\r\n",
        "    else:\r\n",
        "        x = LeakyReLU(alpha=0.2)(x)\r\n",
        "    x = conv(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def decoder_layer(inputs,\r\n",
        "                  paired_inputs,\r\n",
        "                  filters=16,\r\n",
        "                  kernel_size=3,\r\n",
        "                  strides=2,\r\n",
        "                  activation='relu',\r\n",
        "                  instance_norm=True):\r\n",
        "    \"\"\"Builds a generic decoder layer made of Conv2D-IN-LeakyReLU\r\n",
        "    IN is optional, LeakyReLU may be replaced by ReLU\r\n",
        "    Arguments: (partial)\r\n",
        "    inputs (tensor): the decoder layer input\r\n",
        "    paired_inputs (tensor): the encoder layer output \r\n",
        "          provided by U-Net skip connection &\r\n",
        "          concatenated to inputs.\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    conv = Conv2DTranspose(filters=filters,\r\n",
        "                           kernel_size=kernel_size,\r\n",
        "                           strides=strides,\r\n",
        "                           padding='same')\r\n",
        "\r\n",
        "    x = inputs\r\n",
        "    if instance_norm:\r\n",
        "        x = InstanceNormalization()(x)\r\n",
        "    if activation == 'relu':\r\n",
        "        x = Activation('relu')(x)\r\n",
        "    else:\r\n",
        "        x = LeakyReLU(alpha=0.2)(x)\r\n",
        "    x = conv(x)\r\n",
        "    x = concatenate([x, paired_inputs])\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def build_generator(input_shape,\r\n",
        "                    output_shape=None,\r\n",
        "                    kernel_size=3,\r\n",
        "                    name=None):\r\n",
        "    \"\"\"The generator is a U-Network made of a 4-layer encoder\r\n",
        "    and a 4-layer decoder. Layer n-i is connected to layer i.\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    input_shape (tuple): input shape\r\n",
        "    output_shape (tuple): output shape\r\n",
        "    kernel_size (int): kernel size of encoder & decoder layers\r\n",
        "    name (string): name assigned to generator model\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    generator (Model):\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    channels = int(output_shape[-1])\r\n",
        "    e1 = encoder_layer(inputs,\r\n",
        "                       32,\r\n",
        "                       kernel_size=kernel_size,\r\n",
        "                       activation='leaky_relu',\r\n",
        "                       strides=1)\r\n",
        "    e2 = encoder_layer(e1,\r\n",
        "                       64,\r\n",
        "                       activation='leaky_relu',\r\n",
        "                       kernel_size=kernel_size)\r\n",
        "    e3 = encoder_layer(e2,\r\n",
        "                       128,\r\n",
        "                       activation='leaky_relu',\r\n",
        "                       kernel_size=kernel_size)\r\n",
        "    e4 = encoder_layer(e3,\r\n",
        "                       256,\r\n",
        "                       activation='leaky_relu',\r\n",
        "                       kernel_size=kernel_size)\r\n",
        "\r\n",
        "    d1 = decoder_layer(e4,\r\n",
        "                       e3,\r\n",
        "                       128,\r\n",
        "                       kernel_size=kernel_size)\r\n",
        "    d2 = decoder_layer(d1,\r\n",
        "                       e2,\r\n",
        "                       64,\r\n",
        "                       kernel_size=kernel_size)\r\n",
        "    d3 = decoder_layer(d2,\r\n",
        "                       e1,\r\n",
        "                       32,\r\n",
        "                       kernel_size=kernel_size)\r\n",
        "    outputs = Conv2DTranspose(channels,\r\n",
        "                              kernel_size=kernel_size,\r\n",
        "                              strides=1,\r\n",
        "                              activation='sigmoid',\r\n",
        "                              padding='same')(d3)\r\n",
        "\r\n",
        "    generator = Model(inputs, outputs, name=name)\r\n",
        "\r\n",
        "    return generator\r\n",
        "\r\n",
        "\r\n",
        "def build_discriminator(input_shape,\r\n",
        "                        kernel_size=3,\r\n",
        "                        patchgan=True,\r\n",
        "                        name=None):\r\n",
        "    \"\"\"The discriminator is a 4-layer encoder that outputs either\r\n",
        "    a 1-dim or a n x n-dim patch of probability that input is real \r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    input_shape (tuple): input shape\r\n",
        "    kernel_size (int): kernel size of decoder layers\r\n",
        "    patchgan (bool): whether the output is a patch \r\n",
        "        or just a 1-dim\r\n",
        "    name (string): name assigned to discriminator model\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    discriminator (Model):\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    inputs = Input(shape=input_shape)\r\n",
        "    x = encoder_layer(inputs,\r\n",
        "                      32,\r\n",
        "                      kernel_size=kernel_size,\r\n",
        "                      activation='leaky_relu',\r\n",
        "                      instance_norm=False)\r\n",
        "    x = encoder_layer(x,\r\n",
        "                      64,\r\n",
        "                      kernel_size=kernel_size,\r\n",
        "                      activation='leaky_relu',\r\n",
        "                      instance_norm=False)\r\n",
        "    x = encoder_layer(x,\r\n",
        "                      128,\r\n",
        "                      kernel_size=kernel_size,\r\n",
        "                      activation='leaky_relu',\r\n",
        "                      instance_norm=False)\r\n",
        "    x = encoder_layer(x,\r\n",
        "                      256,\r\n",
        "                      kernel_size=kernel_size,\r\n",
        "                      strides=1,\r\n",
        "                      activation='leaky_relu',\r\n",
        "                      instance_norm=False)\r\n",
        "\r\n",
        "    # if patchgan=True use nxn-dim output of probability\r\n",
        "    # else use 1-dim output of probability\r\n",
        "    if patchgan:\r\n",
        "        x = LeakyReLU(alpha=0.2)(x)\r\n",
        "        outputs = Conv2D(1,\r\n",
        "                         kernel_size=kernel_size,\r\n",
        "                         strides=2,\r\n",
        "                         padding='same')(x)\r\n",
        "    else:\r\n",
        "        x = Flatten()(x)\r\n",
        "        x = Dense(1)(x)\r\n",
        "        outputs = Activation('linear')(x)\r\n",
        "\r\n",
        "\r\n",
        "    discriminator = Model(inputs, outputs, name=name)\r\n",
        "\r\n",
        "    return discriminator\r\n",
        "\r\n",
        "\r\n",
        "def train_cyclegan(models,\r\n",
        "                   data,\r\n",
        "                   params,\r\n",
        "                   test_params, \r\n",
        "                   test_generator):\r\n",
        "    \"\"\" Trains the CycleGAN. \r\n",
        "    \r\n",
        "    1) Train the target discriminator\r\n",
        "    2) Train the source discriminator\r\n",
        "    3) Train the forward and backward cyles of \r\n",
        "        adversarial networks\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    models (Models): Source/Target Discriminator/Generator,\r\n",
        "        Adversarial Model\r\n",
        "    data (tuple): source and target training data\r\n",
        "    params (tuple): network parameters\r\n",
        "    test_params (tuple): test parameters\r\n",
        "    test_generator (function): used for generating \r\n",
        "        predicted target and source images\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # the models\r\n",
        "    g_source, g_target, d_source, d_target, adv = models\r\n",
        "    # network parameters\r\n",
        "    batch_size, train_steps, patch, model_name = params\r\n",
        "    # train dataset\r\n",
        "    source_data, target_data, test_source_data, test_target_data\\\r\n",
        "            = data\r\n",
        "\r\n",
        "    titles, dirs = test_params\r\n",
        "\r\n",
        "    # the generator image is saved every 2000 steps\r\n",
        "    save_interval = 2000\r\n",
        "    target_size = target_data.shape[0]\r\n",
        "    source_size = source_data.shape[0]\r\n",
        "\r\n",
        "    # whether to use patchgan or not\r\n",
        "    if patch > 1:\r\n",
        "        d_patch = (patch, patch, 1)\r\n",
        "        valid = np.ones((batch_size,) + d_patch)\r\n",
        "        fake = np.zeros((batch_size,) + d_patch)\r\n",
        "    else:\r\n",
        "        valid = np.ones([batch_size, 1])\r\n",
        "        fake = np.zeros([batch_size, 1])\r\n",
        "\r\n",
        "    valid_fake = np.concatenate((valid, fake))\r\n",
        "    start_time = datetime.datetime.now()\r\n",
        "\r\n",
        "    for step in range(train_steps):\r\n",
        "        # sample a batch of real target data\r\n",
        "        rand_indexes = np.random.randint(0, \r\n",
        "                                         target_size,\r\n",
        "                                         size=batch_size)\r\n",
        "        real_target = target_data[rand_indexes]\r\n",
        "\r\n",
        "        # sample a batch of real source data\r\n",
        "        rand_indexes = np.random.randint(0, \r\n",
        "                                         source_size,\r\n",
        "                                         size=batch_size)\r\n",
        "        real_source = source_data[rand_indexes]\r\n",
        "        # generate a batch of fake target data fr real source data\r\n",
        "        fake_target = g_target.predict(real_source)\r\n",
        "        \r\n",
        "        # combine real and fake into one batch\r\n",
        "        x = np.concatenate((real_target, fake_target))\r\n",
        "        # train the target discriminator using fake/real data\r\n",
        "        metrics = d_target.train_on_batch(x, valid_fake)\r\n",
        "        log = \"%d: [d_target loss: %f]\" % (step, metrics[0])\r\n",
        "\r\n",
        "        # generate a batch of fake source data fr real target data\r\n",
        "        fake_source = g_source.predict(real_target)\r\n",
        "        x = np.concatenate((real_source, fake_source))\r\n",
        "        # train the source discriminator using fake/real data\r\n",
        "        metrics = d_source.train_on_batch(x, valid_fake)\r\n",
        "        log = \"%s [d_source loss: %f]\" % (log, metrics[0])\r\n",
        "\r\n",
        "        # train the adversarial network using forward and backward\r\n",
        "        # cycles. the generated fake source and target \r\n",
        "        # data attempts to trick the discriminators\r\n",
        "        x = [real_source, real_target]\r\n",
        "        y = [valid, valid, real_source, real_target]\r\n",
        "        metrics = adv.train_on_batch(x, y)\r\n",
        "        elapsed_time = datetime.datetime.now() - start_time\r\n",
        "        fmt = \"%s [adv loss: %f] [time: %s]\"\r\n",
        "        log = fmt % (log, metrics[0], elapsed_time)\r\n",
        "        print(log)\r\n",
        "        if (step + 1) % save_interval == 0:\r\n",
        "            test_generator((g_source, g_target),\r\n",
        "                           (test_source_data, test_target_data),\r\n",
        "                           step=step+1,\r\n",
        "                           titles=titles,\r\n",
        "                           dirs=dirs,\r\n",
        "                           show=False)\r\n",
        "\r\n",
        "    # save the models after training the generators\r\n",
        "    g_source.save(model_name + \"-g_source.h5\")\r\n",
        "    g_target.save(model_name + \"-g_target.h5\")\r\n",
        "\r\n",
        "\r\n",
        "def build_cyclegan(shapes,\r\n",
        "                   source_name='source',\r\n",
        "                   target_name='target',\r\n",
        "                   kernel_size=3,\r\n",
        "                   patchgan=False,\r\n",
        "                   identity=False\r\n",
        "                   ):\r\n",
        "    \"\"\"Build the CycleGAN\r\n",
        "\r\n",
        "    1) Build target and source discriminators\r\n",
        "    2) Build target and source generators\r\n",
        "    3) Build the adversarial network\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    shapes (tuple): source and target shapes\r\n",
        "    source_name (string): string to be appended on dis/gen models\r\n",
        "    target_name (string): string to be appended on dis/gen models\r\n",
        "    kernel_size (int): kernel size for the encoder/decoder\r\n",
        "        or dis/gen models\r\n",
        "    patchgan (bool): whether to use patchgan on discriminator\r\n",
        "    identity (bool): whether to use identity loss\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    (list): 2 generator, 2 discriminator, \r\n",
        "        and 1 adversarial models \r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    source_shape, target_shape = shapes\r\n",
        "    lr = 2e-4\r\n",
        "    decay = 6e-8\r\n",
        "    gt_name = \"gen_\" + target_name\r\n",
        "    gs_name = \"gen_\" + source_name\r\n",
        "    dt_name = \"dis_\" + target_name\r\n",
        "    ds_name = \"dis_\" + source_name\r\n",
        "\r\n",
        "    # build target and source generators\r\n",
        "    g_target = build_generator(source_shape,\r\n",
        "                               target_shape,\r\n",
        "                               kernel_size=kernel_size,\r\n",
        "                               name=gt_name)\r\n",
        "    g_source = build_generator(target_shape,\r\n",
        "                               source_shape,\r\n",
        "                               kernel_size=kernel_size,\r\n",
        "                               name=gs_name)\r\n",
        "    print('---- TARGET GENERATOR ----')\r\n",
        "    g_target.summary()\r\n",
        "    print('---- SOURCE GENERATOR ----')\r\n",
        "    g_source.summary()\r\n",
        "\r\n",
        "    # build target and source discriminators\r\n",
        "    d_target = build_discriminator(target_shape,\r\n",
        "                                   patchgan=patchgan,\r\n",
        "                                   kernel_size=kernel_size,\r\n",
        "                                   name=dt_name)\r\n",
        "    d_source = build_discriminator(source_shape,\r\n",
        "                                   patchgan=patchgan,\r\n",
        "                                   kernel_size=kernel_size,\r\n",
        "                                   name=ds_name)\r\n",
        "    print('---- TARGET DISCRIMINATOR ----')\r\n",
        "    d_target.summary()\r\n",
        "    print('---- SOURCE DISCRIMINATOR ----')\r\n",
        "    d_source.summary()\r\n",
        "\r\n",
        "    optimizer = RMSprop(lr=lr, decay=decay)\r\n",
        "    d_target.compile(loss='mse',\r\n",
        "                     optimizer=optimizer,\r\n",
        "                     metrics=['accuracy'])\r\n",
        "    d_source.compile(loss='mse',\r\n",
        "                     optimizer=optimizer,\r\n",
        "                     metrics=['accuracy'])\r\n",
        "\r\n",
        "    d_target.trainable = False\r\n",
        "    d_source.trainable = False\r\n",
        "\r\n",
        "    # build the computational graph for the adversarial model\r\n",
        "    # forward cycle network and target discriminator\r\n",
        "    source_input = Input(shape=source_shape)\r\n",
        "    fake_target = g_target(source_input)\r\n",
        "    preal_target = d_target(fake_target)\r\n",
        "    reco_source = g_source(fake_target)\r\n",
        "\r\n",
        "    # backward cycle network and source discriminator\r\n",
        "    target_input = Input(shape=target_shape)\r\n",
        "    fake_source = g_source(target_input)\r\n",
        "    preal_source = d_source(fake_source)\r\n",
        "    reco_target = g_target(fake_source)\r\n",
        "\r\n",
        "    # if we use identity loss, add 2 extra loss terms\r\n",
        "    # and outputs\r\n",
        "    if identity:\r\n",
        "        iden_source = g_source(source_input)\r\n",
        "        iden_target = g_target(target_input)\r\n",
        "        loss = ['mse', 'mse', 'mae', 'mae', 'mae', 'mae']\r\n",
        "        loss_weights = [1., 1., 10., 10., 0.5, 0.5]\r\n",
        "        inputs = [source_input, target_input]\r\n",
        "        outputs = [preal_source,\r\n",
        "                   preal_target,\r\n",
        "                   reco_source,\r\n",
        "                   reco_target,\r\n",
        "                   iden_source,\r\n",
        "                   iden_target]\r\n",
        "    else:\r\n",
        "        loss = ['mse', 'mse', 'mae', 'mae']\r\n",
        "        loss_weights = [1., 1., 10., 10.]\r\n",
        "        inputs = [source_input, target_input]\r\n",
        "        outputs = [preal_source,\r\n",
        "                   preal_target,\r\n",
        "                   reco_source,\r\n",
        "                   reco_target]\r\n",
        "\r\n",
        "    # build adversarial model\r\n",
        "    adv = Model(inputs, outputs, name='adversarial')\r\n",
        "    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\r\n",
        "    adv.compile(loss=loss,\r\n",
        "                loss_weights=loss_weights,\r\n",
        "                optimizer=optimizer,\r\n",
        "                metrics=['accuracy'])\r\n",
        "    print('---- ADVERSARIAL NETWORK ----')\r\n",
        "    adv.summary()\r\n",
        "\r\n",
        "    return g_source, g_target, d_source, d_target, adv\r\n",
        "\r\n",
        "\r\n",
        "def mnist_cross_svhn(g_models=None):\r\n",
        "    \"\"\"Build and train a CycleGAN that can do mnist <--> svhn\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    model_name = 'cyclegan_mnist_svhn'\r\n",
        "    batch_size = 32\r\n",
        "    train_steps = 500 #100000\r\n",
        "    patchgan = True\r\n",
        "    kernel_size = 5\r\n",
        "    postfix = ('%dp' % kernel_size) \\\r\n",
        "            if patchgan else ('%d' % kernel_size)\r\n",
        "\r\n",
        "    data, shapes = mnist_svhn_load_data()\r\n",
        "    source_data, _, test_source_data, test_target_data = data\r\n",
        "    titles = ('MNIST predicted source images.',\r\n",
        "              'SVHN predicted target images.',\r\n",
        "              'MNIST reconstructed source images.',\r\n",
        "              'SVHN reconstructed target images.')\r\n",
        "    dirs = ('mnist_source-%s' \\\r\n",
        "            % postfix, 'svhn_target-%s' % postfix)\r\n",
        "\r\n",
        "    # generate predicted target(svhn) and source(mnist) images\r\n",
        "    if g_models is not None:\r\n",
        "        g_source, g_target = g_models\r\n",
        "        test_generator_utility((g_source, g_target),\r\n",
        "                                   (test_source_data, \\\r\n",
        "                                           test_target_data),\r\n",
        "                                   step=0,\r\n",
        "                                   titles=titles,\r\n",
        "                                   dirs=dirs,\r\n",
        "                                   show=True)\r\n",
        "        return\r\n",
        "\r\n",
        "    # build the cyclegan for mnist cross svhn\r\n",
        "    models = build_cyclegan(shapes,\r\n",
        "                            \"mnist-%s\" % postfix,\r\n",
        "                            \"svhn-%s\" % postfix,\r\n",
        "                            kernel_size=kernel_size,\r\n",
        "                            patchgan=patchgan)\r\n",
        "    # patch size is divided by 2^n since we downscaled the input\r\n",
        "    # in the discriminator by 2^n (ie. we use strides=2 n times)\r\n",
        "    patch = int(source_data.shape[1] / 2**4) if patchgan else 1\r\n",
        "    params = (batch_size, train_steps, patch, model_name)\r\n",
        "    test_params = (titles, dirs)\r\n",
        "    # train the cyclegan\r\n",
        "    train_cyclegan(models,\r\n",
        "                   data,\r\n",
        "                   params,\r\n",
        "                   test_params,\r\n",
        "                   test_generator_utility)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ4L7hqzVhpN",
        "outputId": "4a4d95c9-e97b-4cf4-c925-30e7a7b84d74"
      },
      "source": [
        "mnist_cross_svhn()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---- TARGET GENERATOR ----\n",
            "Model: \"gen_svhn-5p\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_56 (Inst (None, 32, 32, 1)    2           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)      (None, 32, 32, 1)    0           instance_normalization_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 32, 32, 32)   832         leaky_re_lu_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_57 (Inst (None, 32, 32, 32)   64          conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_73 (LeakyReLU)      (None, 32, 32, 32)   0           instance_normalization_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 16, 16, 64)   51264       leaky_re_lu_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_58 (Inst (None, 16, 16, 64)   128         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_74 (LeakyReLU)      (None, 16, 16, 64)   0           instance_normalization_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 128)    204928      leaky_re_lu_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_59 (Inst (None, 8, 8, 128)    256         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_75 (LeakyReLU)      (None, 8, 8, 128)    0           instance_normalization_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 4, 4, 256)    819456      leaky_re_lu_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_60 (Inst (None, 4, 4, 256)    512         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 256)    0           instance_normalization_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_32 (Conv2DTran (None, 8, 8, 128)    819328      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 8, 8, 256)    0           conv2d_transpose_32[0][0]        \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_61 (Inst (None, 8, 8, 256)    512         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 256)    0           instance_normalization_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_33 (Conv2DTran (None, 16, 16, 64)   409664      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 128)  0           conv2d_transpose_33[0][0]        \n",
            "                                                                 conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_62 (Inst (None, 16, 16, 128)  256         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 128)  0           instance_normalization_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_34 (Conv2DTran (None, 32, 32, 32)   102432      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 32, 32, 64)   0           conv2d_transpose_34[0][0]        \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_35 (Conv2DTran (None, 32, 32, 3)    4803        concatenate_26[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 2,414,437\n",
            "Trainable params: 2,414,437\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "---- SOURCE GENERATOR ----\n",
            "Model: \"gen_mnist-5p\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_26 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_63 (Inst (None, 32, 32, 3)    6           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_76 (LeakyReLU)      (None, 32, 32, 3)    0           instance_normalization_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 32, 32, 32)   2432        leaky_re_lu_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_64 (Inst (None, 32, 32, 32)   64          conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_77 (LeakyReLU)      (None, 32, 32, 32)   0           instance_normalization_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 16, 16, 64)   51264       leaky_re_lu_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_65 (Inst (None, 16, 16, 64)   128         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_78 (LeakyReLU)      (None, 16, 16, 64)   0           instance_normalization_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 128)    204928      leaky_re_lu_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_66 (Inst (None, 8, 8, 128)    256         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_79 (LeakyReLU)      (None, 8, 8, 128)    0           instance_normalization_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 4, 4, 256)    819456      leaky_re_lu_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_67 (Inst (None, 4, 4, 256)    512         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 4, 4, 256)    0           instance_normalization_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_36 (Conv2DTran (None, 8, 8, 128)    819328      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 8, 8, 256)    0           conv2d_transpose_36[0][0]        \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_68 (Inst (None, 8, 8, 256)    512         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 256)    0           instance_normalization_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_37 (Conv2DTran (None, 16, 16, 64)   409664      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 128)  0           conv2d_transpose_37[0][0]        \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "instance_normalization_69 (Inst (None, 16, 16, 128)  256         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 128)  0           instance_normalization_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_38 (Conv2DTran (None, 32, 32, 32)   102432      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 32, 32, 64)   0           conv2d_transpose_38[0][0]        \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_39 (Conv2DTran (None, 32, 32, 1)    1601        concatenate_29[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 2,412,839\n",
            "Trainable params: 2,412,839\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "---- TARGET DISCRIMINATOR ----\n",
            "Model: \"dis_svhn-5p\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_80 (LeakyReLU)   (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 16, 16, 32)        2432      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_81 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_82 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 4, 4, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_83 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_83 (Conv2D)           (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_84 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_84 (Conv2D)           (None, 2, 2, 1)           6401      \n",
            "=================================================================\n",
            "Total params: 1,084,481\n",
            "Trainable params: 1,084,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---- SOURCE DISCRIMINATOR ----\n",
            "Model: \"dis_mnist-5p\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_85 (LeakyReLU)   (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_85 (Conv2D)           (None, 16, 16, 32)        832       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_86 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_86 (Conv2D)           (None, 8, 8, 64)          51264     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_87 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_87 (Conv2D)           (None, 4, 4, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_88 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_88 (Conv2D)           (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_89 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 2, 2, 1)           6401      \n",
            "=================================================================\n",
            "Total params: 1,082,881\n",
            "Trainable params: 1,082,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---- ADVERSARIAL NETWORK ----\n",
            "Model: \"adversarial\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_29 (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gen_mnist-5p (Functional)       (None, 32, 32, 1)    2412839     gen_svhn-5p[0][0]                \n",
            "                                                                 input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gen_svhn-5p (Functional)        (None, 32, 32, 3)    2414437     input_29[0][0]                   \n",
            "                                                                 gen_mnist-5p[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dis_mnist-5p (Functional)       (None, 2, 2, 1)      1082881     gen_mnist-5p[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dis_svhn-5p (Functional)        (None, 2, 2, 1)      1084481     gen_svhn-5p[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 6,994,638\n",
            "Trainable params: 4,827,276\n",
            "Non-trainable params: 2,167,362\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:5 out of the last 3646 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f17c7962ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 8553 calls to <function Model.make_train_function.<locals>.train_function at 0x7f17c67d1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 8554 calls to <function Model.make_train_function.<locals>.train_function at 0x7f17c568d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0: [d_target loss: 0.514124] [d_source loss: 0.501286] [adv loss: 7.729091] [time: 0:00:08.705065]\n",
            "1: [d_target loss: 0.317524] [d_source loss: 0.431584] [adv loss: 5.685774] [time: 0:00:08.827059]\n",
            "2: [d_target loss: 0.425798] [d_source loss: 0.306576] [adv loss: 5.208013] [time: 0:00:08.955508]\n",
            "3: [d_target loss: 0.373838] [d_source loss: 0.209204] [adv loss: 4.989655] [time: 0:00:09.098543]\n",
            "4: [d_target loss: 0.291274] [d_source loss: 0.168579] [adv loss: 4.162010] [time: 0:00:09.242460]\n",
            "5: [d_target loss: 0.274921] [d_source loss: 0.141807] [adv loss: 4.300750] [time: 0:00:09.383931]\n",
            "6: [d_target loss: 0.266824] [d_source loss: 0.142644] [adv loss: 3.962269] [time: 0:00:09.516088]\n",
            "7: [d_target loss: 0.271090] [d_source loss: 0.068570] [adv loss: 3.913468] [time: 0:00:09.653172]\n",
            "8: [d_target loss: 0.274117] [d_source loss: 0.070516] [adv loss: 3.490269] [time: 0:00:09.780899]\n",
            "9: [d_target loss: 0.224720] [d_source loss: 0.073362] [adv loss: 3.460168] [time: 0:00:09.909392]\n",
            "10: [d_target loss: 0.271746] [d_source loss: 0.062946] [adv loss: 3.368465] [time: 0:00:10.039633]\n",
            "11: [d_target loss: 0.228940] [d_source loss: 0.063088] [adv loss: 3.424859] [time: 0:00:10.160357]\n",
            "12: [d_target loss: 0.271415] [d_source loss: 0.063406] [adv loss: 3.586774] [time: 0:00:10.281390]\n",
            "13: [d_target loss: 0.301466] [d_source loss: 0.079467] [adv loss: 2.999169] [time: 0:00:10.401299]\n",
            "14: [d_target loss: 0.253241] [d_source loss: 0.138169] [adv loss: 3.565570] [time: 0:00:10.525330]\n",
            "15: [d_target loss: 0.269523] [d_source loss: 0.142036] [adv loss: 3.342789] [time: 0:00:10.641171]\n",
            "16: [d_target loss: 0.262706] [d_source loss: 0.093066] [adv loss: 3.146370] [time: 0:00:10.767627]\n",
            "17: [d_target loss: 0.239067] [d_source loss: 0.088080] [adv loss: 2.882964] [time: 0:00:10.884436]\n",
            "18: [d_target loss: 0.253828] [d_source loss: 0.082022] [adv loss: 3.317607] [time: 0:00:11.003110]\n",
            "19: [d_target loss: 0.256215] [d_source loss: 0.083401] [adv loss: 3.079939] [time: 0:00:11.140369]\n",
            "20: [d_target loss: 0.275250] [d_source loss: 0.095429] [adv loss: 3.773748] [time: 0:00:11.264647]\n",
            "21: [d_target loss: 0.323858] [d_source loss: 0.077753] [adv loss: 3.074051] [time: 0:00:11.382132]\n",
            "22: [d_target loss: 0.276458] [d_source loss: 0.097618] [adv loss: 3.090029] [time: 0:00:11.498729]\n",
            "23: [d_target loss: 0.250513] [d_source loss: 0.095415] [adv loss: 2.814890] [time: 0:00:11.618837]\n",
            "24: [d_target loss: 0.282854] [d_source loss: 0.085567] [adv loss: 3.514322] [time: 0:00:11.748106]\n",
            "25: [d_target loss: 0.271367] [d_source loss: 0.131620] [adv loss: 2.653259] [time: 0:00:11.869825]\n",
            "26: [d_target loss: 0.250659] [d_source loss: 0.074521] [adv loss: 3.041094] [time: 0:00:11.984320]\n",
            "27: [d_target loss: 0.259233] [d_source loss: 0.075351] [adv loss: 2.665402] [time: 0:00:12.104803]\n",
            "28: [d_target loss: 0.269875] [d_source loss: 0.085878] [adv loss: 3.228006] [time: 0:00:12.230583]\n",
            "29: [d_target loss: 0.268401] [d_source loss: 0.112485] [adv loss: 2.501122] [time: 0:00:12.349784]\n",
            "30: [d_target loss: 0.292942] [d_source loss: 0.104533] [adv loss: 3.216635] [time: 0:00:12.464996]\n",
            "31: [d_target loss: 0.275391] [d_source loss: 0.125972] [adv loss: 2.539288] [time: 0:00:12.580659]\n",
            "32: [d_target loss: 0.250623] [d_source loss: 0.087523] [adv loss: 3.003237] [time: 0:00:12.699304]\n",
            "33: [d_target loss: 0.241372] [d_source loss: 0.109155] [adv loss: 2.418135] [time: 0:00:12.825883]\n",
            "34: [d_target loss: 0.273068] [d_source loss: 0.098587] [adv loss: 3.126785] [time: 0:00:12.942186]\n",
            "35: [d_target loss: 0.274897] [d_source loss: 0.115963] [adv loss: 2.565080] [time: 0:00:13.060173]\n",
            "36: [d_target loss: 0.282157] [d_source loss: 0.108000] [adv loss: 3.022917] [time: 0:00:13.181050]\n",
            "37: [d_target loss: 0.276143] [d_source loss: 0.127742] [adv loss: 2.586370] [time: 0:00:13.300245]\n",
            "38: [d_target loss: 0.251340] [d_source loss: 0.105156] [adv loss: 3.163130] [time: 0:00:13.421267]\n",
            "39: [d_target loss: 0.280740] [d_source loss: 0.116152] [adv loss: 2.515927] [time: 0:00:13.540336]\n",
            "40: [d_target loss: 0.261787] [d_source loss: 0.104593] [adv loss: 2.888177] [time: 0:00:13.656927]\n",
            "41: [d_target loss: 0.234271] [d_source loss: 0.118179] [adv loss: 2.559861] [time: 0:00:13.790990]\n",
            "42: [d_target loss: 0.306476] [d_source loss: 0.131644] [adv loss: 3.077064] [time: 0:00:13.918433]\n",
            "43: [d_target loss: 0.284074] [d_source loss: 0.155568] [adv loss: 2.384670] [time: 0:00:14.047072]\n",
            "44: [d_target loss: 0.233417] [d_source loss: 0.135975] [adv loss: 3.074733] [time: 0:00:14.167012]\n",
            "45: [d_target loss: 0.238188] [d_source loss: 0.153661] [adv loss: 2.302702] [time: 0:00:14.291931]\n",
            "46: [d_target loss: 0.264467] [d_source loss: 0.138888] [adv loss: 2.923744] [time: 0:00:14.418501]\n",
            "47: [d_target loss: 0.288413] [d_source loss: 0.118899] [adv loss: 2.214919] [time: 0:00:14.546045]\n",
            "48: [d_target loss: 0.281289] [d_source loss: 0.133242] [adv loss: 2.552075] [time: 0:00:14.671633]\n",
            "49: [d_target loss: 0.232365] [d_source loss: 0.112514] [adv loss: 2.383731] [time: 0:00:14.795764]\n",
            "50: [d_target loss: 0.268295] [d_source loss: 0.159796] [adv loss: 2.976681] [time: 0:00:14.926498]\n",
            "51: [d_target loss: 0.288591] [d_source loss: 0.170229] [adv loss: 2.368942] [time: 0:00:15.041447]\n",
            "52: [d_target loss: 0.281483] [d_source loss: 0.137296] [adv loss: 2.621368] [time: 0:00:15.170185]\n",
            "53: [d_target loss: 0.262318] [d_source loss: 0.147590] [adv loss: 2.269650] [time: 0:00:15.285423]\n",
            "54: [d_target loss: 0.268876] [d_source loss: 0.142441] [adv loss: 2.538454] [time: 0:00:15.405632]\n",
            "55: [d_target loss: 0.249942] [d_source loss: 0.158672] [adv loss: 2.238288] [time: 0:00:15.524994]\n",
            "56: [d_target loss: 0.269575] [d_source loss: 0.143247] [adv loss: 2.797424] [time: 0:00:15.642445]\n",
            "57: [d_target loss: 0.267766] [d_source loss: 0.142152] [adv loss: 2.434710] [time: 0:00:15.777439]\n",
            "58: [d_target loss: 0.280059] [d_source loss: 0.158059] [adv loss: 2.505399] [time: 0:00:15.902132]\n",
            "59: [d_target loss: 0.262604] [d_source loss: 0.171855] [adv loss: 2.017412] [time: 0:00:16.017016]\n",
            "60: [d_target loss: 0.274672] [d_source loss: 0.151109] [adv loss: 3.157312] [time: 0:00:16.134273]\n",
            "61: [d_target loss: 0.255692] [d_source loss: 0.186696] [adv loss: 2.373292] [time: 0:00:16.252248]\n",
            "62: [d_target loss: 0.269022] [d_source loss: 0.168273] [adv loss: 2.616598] [time: 0:00:16.379840]\n",
            "63: [d_target loss: 0.264758] [d_source loss: 0.166183] [adv loss: 2.210177] [time: 0:00:16.511195]\n",
            "64: [d_target loss: 0.263583] [d_source loss: 0.161134] [adv loss: 2.673021] [time: 0:00:16.638900]\n",
            "65: [d_target loss: 0.255918] [d_source loss: 0.159141] [adv loss: 2.047477] [time: 0:00:16.757244]\n",
            "66: [d_target loss: 0.269603] [d_source loss: 0.151813] [adv loss: 2.705986] [time: 0:00:16.875078]\n",
            "67: [d_target loss: 0.243330] [d_source loss: 0.150262] [adv loss: 2.158448] [time: 0:00:17.006534]\n",
            "68: [d_target loss: 0.281575] [d_source loss: 0.171752] [adv loss: 2.677705] [time: 0:00:17.147246]\n",
            "69: [d_target loss: 0.294115] [d_source loss: 0.159048] [adv loss: 2.174521] [time: 0:00:17.265653]\n",
            "70: [d_target loss: 0.261864] [d_source loss: 0.177820] [adv loss: 2.767941] [time: 0:00:17.383574]\n",
            "71: [d_target loss: 0.258590] [d_source loss: 0.195089] [adv loss: 1.775087] [time: 0:00:17.499658]\n",
            "72: [d_target loss: 0.255145] [d_source loss: 0.192355] [adv loss: 2.594545] [time: 0:00:17.626385]\n",
            "73: [d_target loss: 0.244574] [d_source loss: 0.209120] [adv loss: 2.134007] [time: 0:00:17.744268]\n",
            "74: [d_target loss: 0.246354] [d_source loss: 0.165505] [adv loss: 2.729262] [time: 0:00:17.860493]\n",
            "75: [d_target loss: 0.253936] [d_source loss: 0.189895] [adv loss: 2.226966] [time: 0:00:17.978845]\n",
            "76: [d_target loss: 0.251537] [d_source loss: 0.185641] [adv loss: 2.698357] [time: 0:00:18.105107]\n",
            "77: [d_target loss: 0.241193] [d_source loss: 0.208106] [adv loss: 2.334721] [time: 0:00:18.224209]\n",
            "78: [d_target loss: 0.256744] [d_source loss: 0.167217] [adv loss: 2.953064] [time: 0:00:18.336128]\n",
            "79: [d_target loss: 0.274535] [d_source loss: 0.204968] [adv loss: 2.391558] [time: 0:00:18.456177]\n",
            "80: [d_target loss: 0.242082] [d_source loss: 0.181276] [adv loss: 2.690266] [time: 0:00:18.573904]\n",
            "81: [d_target loss: 0.251413] [d_source loss: 0.167279] [adv loss: 2.147803] [time: 0:00:18.695758]\n",
            "82: [d_target loss: 0.229430] [d_source loss: 0.189157] [adv loss: 2.707305] [time: 0:00:18.820383]\n",
            "83: [d_target loss: 0.237566] [d_source loss: 0.191744] [adv loss: 2.242588] [time: 0:00:18.940236]\n",
            "84: [d_target loss: 0.250928] [d_source loss: 0.177481] [adv loss: 2.765340] [time: 0:00:19.058967]\n",
            "85: [d_target loss: 0.269185] [d_source loss: 0.173267] [adv loss: 2.225902] [time: 0:00:19.178181]\n",
            "86: [d_target loss: 0.249130] [d_source loss: 0.162266] [adv loss: 2.559381] [time: 0:00:19.319261]\n",
            "87: [d_target loss: 0.255746] [d_source loss: 0.162907] [adv loss: 2.189639] [time: 0:00:19.436806]\n",
            "88: [d_target loss: 0.224374] [d_source loss: 0.166677] [adv loss: 2.747203] [time: 0:00:19.554866]\n",
            "89: [d_target loss: 0.247336] [d_source loss: 0.214213] [adv loss: 2.157605] [time: 0:00:19.673805]\n",
            "90: [d_target loss: 0.243855] [d_source loss: 0.174446] [adv loss: 2.850821] [time: 0:00:19.789933]\n",
            "91: [d_target loss: 0.277260] [d_source loss: 0.231587] [adv loss: 2.252054] [time: 0:00:19.911517]\n",
            "92: [d_target loss: 0.246433] [d_source loss: 0.171475] [adv loss: 2.568909] [time: 0:00:20.038779]\n",
            "93: [d_target loss: 0.243512] [d_source loss: 0.179900] [adv loss: 2.248679] [time: 0:00:20.158177]\n",
            "94: [d_target loss: 0.249987] [d_source loss: 0.176688] [adv loss: 3.005941] [time: 0:00:20.275614]\n",
            "95: [d_target loss: 0.277645] [d_source loss: 0.204575] [adv loss: 2.294976] [time: 0:00:20.392052]\n",
            "96: [d_target loss: 0.248375] [d_source loss: 0.171502] [adv loss: 2.487899] [time: 0:00:20.517923]\n",
            "97: [d_target loss: 0.216539] [d_source loss: 0.192187] [adv loss: 2.361250] [time: 0:00:20.636028]\n",
            "98: [d_target loss: 0.225148] [d_source loss: 0.197879] [adv loss: 2.612215] [time: 0:00:20.754706]\n",
            "99: [d_target loss: 0.231046] [d_source loss: 0.204600] [adv loss: 2.107537] [time: 0:00:20.874310]\n",
            "100: [d_target loss: 0.268655] [d_source loss: 0.185921] [adv loss: 2.778557] [time: 0:00:20.999711]\n",
            "101: [d_target loss: 0.269642] [d_source loss: 0.194144] [adv loss: 2.187891] [time: 0:00:21.121147]\n",
            "102: [d_target loss: 0.229346] [d_source loss: 0.188728] [adv loss: 2.544462] [time: 0:00:21.237951]\n",
            "103: [d_target loss: 0.231729] [d_source loss: 0.222194] [adv loss: 2.231508] [time: 0:00:21.356351]\n",
            "104: [d_target loss: 0.232048] [d_source loss: 0.175033] [adv loss: 2.556538] [time: 0:00:21.472350]\n",
            "105: [d_target loss: 0.238811] [d_source loss: 0.208085] [adv loss: 2.142771] [time: 0:00:21.598254]\n",
            "106: [d_target loss: 0.223679] [d_source loss: 0.197459] [adv loss: 2.482620] [time: 0:00:21.729389]\n",
            "107: [d_target loss: 0.195146] [d_source loss: 0.181974] [adv loss: 2.273165] [time: 0:00:21.851695]\n",
            "108: [d_target loss: 0.221106] [d_source loss: 0.193066] [adv loss: 2.487342] [time: 0:00:21.969199]\n",
            "109: [d_target loss: 0.217564] [d_source loss: 0.195481] [adv loss: 2.270604] [time: 0:00:22.090048]\n",
            "110: [d_target loss: 0.221874] [d_source loss: 0.191355] [adv loss: 2.640082] [time: 0:00:22.216964]\n",
            "111: [d_target loss: 0.211760] [d_source loss: 0.203421] [adv loss: 2.029692] [time: 0:00:22.333038]\n",
            "112: [d_target loss: 0.372071] [d_source loss: 0.207683] [adv loss: 2.923642] [time: 0:00:22.449651]\n",
            "113: [d_target loss: 0.300004] [d_source loss: 0.219113] [adv loss: 2.175134] [time: 0:00:22.567457]\n",
            "114: [d_target loss: 0.348780] [d_source loss: 0.201098] [adv loss: 2.733301] [time: 0:00:22.697562]\n",
            "115: [d_target loss: 0.322649] [d_source loss: 0.167093] [adv loss: 2.224227] [time: 0:00:22.844597]\n",
            "116: [d_target loss: 0.290141] [d_source loss: 0.165687] [adv loss: 2.408197] [time: 0:00:22.975052]\n",
            "117: [d_target loss: 0.245091] [d_source loss: 0.200133] [adv loss: 2.558831] [time: 0:00:23.096809]\n",
            "118: [d_target loss: 0.251444] [d_source loss: 0.180009] [adv loss: 2.657043] [time: 0:00:23.215607]\n",
            "119: [d_target loss: 0.230808] [d_source loss: 0.192035] [adv loss: 2.334190] [time: 0:00:23.333512]\n",
            "120: [d_target loss: 0.242054] [d_source loss: 0.194186] [adv loss: 2.544707] [time: 0:00:23.454174]\n",
            "121: [d_target loss: 0.212428] [d_source loss: 0.191738] [adv loss: 2.472173] [time: 0:00:23.571983]\n",
            "122: [d_target loss: 0.223406] [d_source loss: 0.216082] [adv loss: 2.652694] [time: 0:00:23.691838]\n",
            "123: [d_target loss: 0.242907] [d_source loss: 0.234673] [adv loss: 2.648968] [time: 0:00:23.813001]\n",
            "124: [d_target loss: 0.235037] [d_source loss: 0.203276] [adv loss: 2.489475] [time: 0:00:23.937660]\n",
            "125: [d_target loss: 0.248263] [d_source loss: 0.179401] [adv loss: 2.304250] [time: 0:00:24.053433]\n",
            "126: [d_target loss: 0.256166] [d_source loss: 0.208104] [adv loss: 2.445409] [time: 0:00:24.172330]\n",
            "127: [d_target loss: 0.268771] [d_source loss: 0.218185] [adv loss: 2.558723] [time: 0:00:24.295531]\n",
            "128: [d_target loss: 0.284273] [d_source loss: 0.205782] [adv loss: 2.389613] [time: 0:00:24.410439]\n",
            "129: [d_target loss: 0.238423] [d_source loss: 0.181739] [adv loss: 2.271224] [time: 0:00:24.533697]\n",
            "130: [d_target loss: 0.228652] [d_source loss: 0.182851] [adv loss: 2.485241] [time: 0:00:24.650110]\n",
            "131: [d_target loss: 0.237460] [d_source loss: 0.188496] [adv loss: 2.392845] [time: 0:00:24.770394]\n",
            "132: [d_target loss: 0.202162] [d_source loss: 0.196943] [adv loss: 2.813990] [time: 0:00:24.894692]\n",
            "133: [d_target loss: 0.238338] [d_source loss: 0.229257] [adv loss: 2.068716] [time: 0:00:25.015742]\n",
            "134: [d_target loss: 0.221772] [d_source loss: 0.205458] [adv loss: 2.749786] [time: 0:00:25.154216]\n",
            "135: [d_target loss: 0.252397] [d_source loss: 0.226717] [adv loss: 2.111657] [time: 0:00:25.278893]\n",
            "136: [d_target loss: 0.246072] [d_source loss: 0.191752] [adv loss: 2.587025] [time: 0:00:25.398088]\n",
            "137: [d_target loss: 0.256292] [d_source loss: 0.167715] [adv loss: 2.359377] [time: 0:00:25.516099]\n",
            "138: [d_target loss: 0.253786] [d_source loss: 0.202255] [adv loss: 2.700356] [time: 0:00:25.635113]\n",
            "139: [d_target loss: 0.214761] [d_source loss: 0.191590] [adv loss: 2.337501] [time: 0:00:25.760964]\n",
            "140: [d_target loss: 0.337902] [d_source loss: 0.191688] [adv loss: 3.024505] [time: 0:00:25.889341]\n",
            "141: [d_target loss: 0.247581] [d_source loss: 0.238008] [adv loss: 2.437731] [time: 0:00:26.009149]\n",
            "142: [d_target loss: 0.250466] [d_source loss: 0.223400] [adv loss: 2.847162] [time: 0:00:26.128877]\n",
            "143: [d_target loss: 0.284840] [d_source loss: 0.264050] [adv loss: 2.190029] [time: 0:00:26.245570]\n",
            "144: [d_target loss: 0.239195] [d_source loss: 0.202895] [adv loss: 2.686128] [time: 0:00:26.371841]\n",
            "145: [d_target loss: 0.228304] [d_source loss: 0.190777] [adv loss: 2.247733] [time: 0:00:26.489701]\n",
            "146: [d_target loss: 0.238321] [d_source loss: 0.186963] [adv loss: 2.617293] [time: 0:00:26.609732]\n",
            "147: [d_target loss: 0.245654] [d_source loss: 0.168473] [adv loss: 2.257919] [time: 0:00:26.724882]\n",
            "148: [d_target loss: 0.245690] [d_source loss: 0.167760] [adv loss: 2.372817] [time: 0:00:26.846973]\n",
            "149: [d_target loss: 0.242104] [d_source loss: 0.186341] [adv loss: 2.288187] [time: 0:00:26.963324]\n",
            "150: [d_target loss: 0.257200] [d_source loss: 0.166063] [adv loss: 2.241590] [time: 0:00:27.079928]\n",
            "151: [d_target loss: 0.223912] [d_source loss: 0.165677] [adv loss: 2.570413] [time: 0:00:27.198416]\n",
            "152: [d_target loss: 0.243055] [d_source loss: 0.209128] [adv loss: 2.094095] [time: 0:00:27.317262]\n",
            "153: [d_target loss: 0.229763] [d_source loss: 0.261929] [adv loss: 2.860830] [time: 0:00:27.440453]\n",
            "154: [d_target loss: 0.214171] [d_source loss: 0.320721] [adv loss: 2.506095] [time: 0:00:27.564341]\n",
            "155: [d_target loss: 0.271857] [d_source loss: 0.198126] [adv loss: 2.350311] [time: 0:00:27.685010]\n",
            "156: [d_target loss: 0.229350] [d_source loss: 0.187812] [adv loss: 2.257092] [time: 0:00:27.802674]\n",
            "157: [d_target loss: 0.231076] [d_source loss: 0.196808] [adv loss: 2.445434] [time: 0:00:27.928038]\n",
            "158: [d_target loss: 0.227661] [d_source loss: 0.186381] [adv loss: 2.452546] [time: 0:00:28.057890]\n",
            "159: [d_target loss: 0.217017] [d_source loss: 0.188921] [adv loss: 2.284929] [time: 0:00:28.177197]\n",
            "160: [d_target loss: 0.219362] [d_source loss: 0.182872] [adv loss: 2.531148] [time: 0:00:28.297163]\n",
            "161: [d_target loss: 0.235150] [d_source loss: 0.190165] [adv loss: 2.091801] [time: 0:00:28.414466]\n",
            "162: [d_target loss: 0.258459] [d_source loss: 0.211394] [adv loss: 3.121900] [time: 0:00:28.530015]\n",
            "163: [d_target loss: 0.308900] [d_source loss: 0.210753] [adv loss: 2.288660] [time: 0:00:28.655418]\n",
            "164: [d_target loss: 0.284817] [d_source loss: 0.175794] [adv loss: 2.760576] [time: 0:00:28.771623]\n",
            "165: [d_target loss: 0.257055] [d_source loss: 0.210723] [adv loss: 2.227249] [time: 0:00:28.887112]\n",
            "166: [d_target loss: 0.225352] [d_source loss: 0.171640] [adv loss: 2.510239] [time: 0:00:29.002867]\n",
            "167: [d_target loss: 0.233994] [d_source loss: 0.232483] [adv loss: 2.514894] [time: 0:00:29.122056]\n",
            "168: [d_target loss: 0.240089] [d_source loss: 0.177820] [adv loss: 2.662133] [time: 0:00:29.246383]\n",
            "169: [d_target loss: 0.230805] [d_source loss: 0.207772] [adv loss: 2.385214] [time: 0:00:29.361745]\n",
            "170: [d_target loss: 0.228817] [d_source loss: 0.180368] [adv loss: 2.207751] [time: 0:00:29.479283]\n",
            "171: [d_target loss: 0.222393] [d_source loss: 0.173695] [adv loss: 2.512601] [time: 0:00:29.596018]\n",
            "172: [d_target loss: 0.239958] [d_source loss: 0.175935] [adv loss: 2.674636] [time: 0:00:29.716942]\n",
            "173: [d_target loss: 0.244413] [d_source loss: 0.210875] [adv loss: 2.265979] [time: 0:00:29.831836]\n",
            "174: [d_target loss: 0.253043] [d_source loss: 0.248302] [adv loss: 2.983674] [time: 0:00:29.956087]\n",
            "175: [d_target loss: 0.204450] [d_source loss: 0.294008] [adv loss: 2.184580] [time: 0:00:30.086186]\n",
            "176: [d_target loss: 0.239297] [d_source loss: 0.183686] [adv loss: 2.702725] [time: 0:00:30.215489]\n",
            "177: [d_target loss: 0.220448] [d_source loss: 0.190560] [adv loss: 2.226192] [time: 0:00:30.349767]\n",
            "178: [d_target loss: 0.286278] [d_source loss: 0.179586] [adv loss: 2.819146] [time: 0:00:30.482309]\n",
            "179: [d_target loss: 0.235412] [d_source loss: 0.193421] [adv loss: 2.155180] [time: 0:00:30.609018]\n",
            "180: [d_target loss: 0.279819] [d_source loss: 0.185993] [adv loss: 2.659079] [time: 0:00:30.726391]\n",
            "181: [d_target loss: 0.276840] [d_source loss: 0.205759] [adv loss: 2.130702] [time: 0:00:30.848549]\n",
            "182: [d_target loss: 0.253116] [d_source loss: 0.221582] [adv loss: 2.561913] [time: 0:00:30.993948]\n",
            "183: [d_target loss: 0.234243] [d_source loss: 0.257938] [adv loss: 2.279180] [time: 0:00:31.125524]\n",
            "184: [d_target loss: 0.254517] [d_source loss: 0.219743] [adv loss: 2.392557] [time: 0:00:31.260352]\n",
            "185: [d_target loss: 0.231529] [d_source loss: 0.192743] [adv loss: 2.154173] [time: 0:00:31.388229]\n",
            "186: [d_target loss: 0.230489] [d_source loss: 0.207297] [adv loss: 2.303922] [time: 0:00:31.515807]\n",
            "187: [d_target loss: 0.226597] [d_source loss: 0.201615] [adv loss: 2.256960] [time: 0:00:31.643388]\n",
            "188: [d_target loss: 0.206564] [d_source loss: 0.194538] [adv loss: 2.660334] [time: 0:00:31.762949]\n",
            "189: [d_target loss: 0.236693] [d_source loss: 0.201055] [adv loss: 2.377537] [time: 0:00:31.881129]\n",
            "190: [d_target loss: 0.218085] [d_source loss: 0.186895] [adv loss: 2.526350] [time: 0:00:32.006633]\n",
            "191: [d_target loss: 0.266054] [d_source loss: 0.211761] [adv loss: 2.443154] [time: 0:00:32.131412]\n",
            "192: [d_target loss: 0.261364] [d_source loss: 0.204187] [adv loss: 2.554994] [time: 0:00:32.261764]\n",
            "193: [d_target loss: 0.246033] [d_source loss: 0.207231] [adv loss: 2.226007] [time: 0:00:32.378584]\n",
            "194: [d_target loss: 0.262027] [d_source loss: 0.187940] [adv loss: 2.359113] [time: 0:00:32.497230]\n",
            "195: [d_target loss: 0.215369] [d_source loss: 0.193373] [adv loss: 2.263827] [time: 0:00:32.621240]\n",
            "196: [d_target loss: 0.210358] [d_source loss: 0.183323] [adv loss: 2.589305] [time: 0:00:32.742723]\n",
            "197: [d_target loss: 0.211595] [d_source loss: 0.206142] [adv loss: 2.191458] [time: 0:00:32.863449]\n",
            "198: [d_target loss: 0.212324] [d_source loss: 0.181151] [adv loss: 2.753046] [time: 0:00:32.991168]\n",
            "199: [d_target loss: 0.223706] [d_source loss: 0.191750] [adv loss: 2.475938] [time: 0:00:33.108767]\n",
            "200: [d_target loss: 0.221954] [d_source loss: 0.197173] [adv loss: 2.923663] [time: 0:00:33.250053]\n",
            "201: [d_target loss: 0.217162] [d_source loss: 0.222571] [adv loss: 2.366446] [time: 0:00:33.371039]\n",
            "202: [d_target loss: 0.212420] [d_source loss: 0.196961] [adv loss: 2.878097] [time: 0:00:33.490969]\n",
            "203: [d_target loss: 0.227341] [d_source loss: 0.232552] [adv loss: 2.344340] [time: 0:00:33.611102]\n",
            "204: [d_target loss: 0.273920] [d_source loss: 0.221291] [adv loss: 2.485074] [time: 0:00:33.730245]\n",
            "205: [d_target loss: 0.230501] [d_source loss: 0.208302] [adv loss: 2.338291] [time: 0:00:33.849636]\n",
            "206: [d_target loss: 0.249501] [d_source loss: 0.215475] [adv loss: 2.671504] [time: 0:00:33.981957]\n",
            "207: [d_target loss: 0.223938] [d_source loss: 0.231766] [adv loss: 2.095482] [time: 0:00:34.103143]\n",
            "208: [d_target loss: 0.235382] [d_source loss: 0.207290] [adv loss: 2.592963] [time: 0:00:34.223739]\n",
            "209: [d_target loss: 0.250355] [d_source loss: 0.187954] [adv loss: 2.141190] [time: 0:00:34.342802]\n",
            "210: [d_target loss: 0.208785] [d_source loss: 0.179369] [adv loss: 2.637755] [time: 0:00:34.469956]\n",
            "211: [d_target loss: 0.227960] [d_source loss: 0.170586] [adv loss: 2.038560] [time: 0:00:34.593868]\n",
            "212: [d_target loss: 0.236685] [d_source loss: 0.159250] [adv loss: 2.589533] [time: 0:00:34.720352]\n",
            "213: [d_target loss: 0.217993] [d_source loss: 0.185440] [adv loss: 2.116473] [time: 0:00:34.838655]\n",
            "214: [d_target loss: 0.204985] [d_source loss: 0.188501] [adv loss: 2.673741] [time: 0:00:34.969416]\n",
            "215: [d_target loss: 0.213085] [d_source loss: 0.199525] [adv loss: 2.241749] [time: 0:00:35.101589]\n",
            "216: [d_target loss: 0.225177] [d_source loss: 0.187253] [adv loss: 2.667979] [time: 0:00:35.235453]\n",
            "217: [d_target loss: 0.213986] [d_source loss: 0.213332] [adv loss: 2.489944] [time: 0:00:35.356911]\n",
            "218: [d_target loss: 0.291277] [d_source loss: 0.207124] [adv loss: 2.961145] [time: 0:00:35.477027]\n",
            "219: [d_target loss: 0.244625] [d_source loss: 0.235054] [adv loss: 2.117739] [time: 0:00:35.597904]\n",
            "220: [d_target loss: 0.390045] [d_source loss: 0.203711] [adv loss: 2.882239] [time: 0:00:35.726149]\n",
            "221: [d_target loss: 0.264643] [d_source loss: 0.239767] [adv loss: 2.457797] [time: 0:00:35.846274]\n",
            "222: [d_target loss: 0.247920] [d_source loss: 0.173909] [adv loss: 2.588327] [time: 0:00:35.964367]\n",
            "223: [d_target loss: 0.242748] [d_source loss: 0.178706] [adv loss: 2.167357] [time: 0:00:36.092557]\n",
            "224: [d_target loss: 0.247540] [d_source loss: 0.194356] [adv loss: 2.499520] [time: 0:00:36.214308]\n",
            "225: [d_target loss: 0.215283] [d_source loss: 0.195498] [adv loss: 2.066013] [time: 0:00:36.339318]\n",
            "226: [d_target loss: 0.269249] [d_source loss: 0.206474] [adv loss: 2.753545] [time: 0:00:36.461870]\n",
            "227: [d_target loss: 0.245612] [d_source loss: 0.220158] [adv loss: 2.231863] [time: 0:00:36.579414]\n",
            "228: [d_target loss: 0.239775] [d_source loss: 0.187142] [adv loss: 2.415483] [time: 0:00:36.701997]\n",
            "229: [d_target loss: 0.209492] [d_source loss: 0.188030] [adv loss: 2.294551] [time: 0:00:36.822303]\n",
            "230: [d_target loss: 0.220162] [d_source loss: 0.196006] [adv loss: 2.506400] [time: 0:00:36.951397]\n",
            "231: [d_target loss: 0.230833] [d_source loss: 0.192173] [adv loss: 2.269905] [time: 0:00:37.084231]\n",
            "232: [d_target loss: 0.237474] [d_source loss: 0.200208] [adv loss: 2.814101] [time: 0:00:37.217425]\n",
            "233: [d_target loss: 0.221458] [d_source loss: 0.229546] [adv loss: 2.244925] [time: 0:00:37.347629]\n",
            "234: [d_target loss: 0.218076] [d_source loss: 0.200952] [adv loss: 2.755538] [time: 0:00:37.476811]\n",
            "235: [d_target loss: 0.205084] [d_source loss: 0.214101] [adv loss: 2.132254] [time: 0:00:37.603679]\n",
            "236: [d_target loss: 0.451194] [d_source loss: 0.225226] [adv loss: 3.035416] [time: 0:00:37.725141]\n",
            "237: [d_target loss: 0.277233] [d_source loss: 0.221247] [adv loss: 2.417285] [time: 0:00:37.841401]\n",
            "238: [d_target loss: 0.234100] [d_source loss: 0.173206] [adv loss: 2.430877] [time: 0:00:37.962271]\n",
            "239: [d_target loss: 0.265983] [d_source loss: 0.181884] [adv loss: 2.538082] [time: 0:00:38.093760]\n",
            "240: [d_target loss: 0.249609] [d_source loss: 0.180833] [adv loss: 2.232750] [time: 0:00:38.224442]\n",
            "241: [d_target loss: 0.270212] [d_source loss: 0.183097] [adv loss: 2.319306] [time: 0:00:38.345207]\n",
            "242: [d_target loss: 0.238173] [d_source loss: 0.199955] [adv loss: 2.588758] [time: 0:00:38.466237]\n",
            "243: [d_target loss: 0.245033] [d_source loss: 0.228049] [adv loss: 2.319289] [time: 0:00:38.587848]\n",
            "244: [d_target loss: 0.223497] [d_source loss: 0.209386] [adv loss: 2.780382] [time: 0:00:38.717155]\n",
            "245: [d_target loss: 0.230732] [d_source loss: 0.231681] [adv loss: 2.222943] [time: 0:00:38.835458]\n",
            "246: [d_target loss: 0.227712] [d_source loss: 0.184286] [adv loss: 2.289615] [time: 0:00:38.958442]\n",
            "247: [d_target loss: 0.213172] [d_source loss: 0.180162] [adv loss: 2.415136] [time: 0:00:39.085476]\n",
            "248: [d_target loss: 0.200850] [d_source loss: 0.186613] [adv loss: 2.279251] [time: 0:00:39.211138]\n",
            "249: [d_target loss: 0.215840] [d_source loss: 0.196649] [adv loss: 2.389961] [time: 0:00:39.340254]\n",
            "250: [d_target loss: 0.212926] [d_source loss: 0.190683] [adv loss: 2.729118] [time: 0:00:39.463785]\n",
            "251: [d_target loss: 0.216870] [d_source loss: 0.186659] [adv loss: 2.306193] [time: 0:00:39.578586]\n",
            "252: [d_target loss: 0.252826] [d_source loss: 0.206823] [adv loss: 2.358197] [time: 0:00:39.696056]\n",
            "253: [d_target loss: 0.233640] [d_source loss: 0.190759] [adv loss: 2.210593] [time: 0:00:39.817406]\n",
            "254: [d_target loss: 0.223459] [d_source loss: 0.205196] [adv loss: 2.781745] [time: 0:00:39.945236]\n",
            "255: [d_target loss: 0.210599] [d_source loss: 0.237917] [adv loss: 2.204825] [time: 0:00:40.068631]\n",
            "256: [d_target loss: 0.226621] [d_source loss: 0.207518] [adv loss: 2.681051] [time: 0:00:40.190325]\n",
            "257: [d_target loss: 0.223136] [d_source loss: 0.246515] [adv loss: 2.259287] [time: 0:00:40.307848]\n",
            "258: [d_target loss: 0.184530] [d_source loss: 0.170420] [adv loss: 2.827937] [time: 0:00:40.430861]\n",
            "259: [d_target loss: 0.184287] [d_source loss: 0.180234] [adv loss: 2.376827] [time: 0:00:40.553957]\n",
            "260: [d_target loss: 0.312093] [d_source loss: 0.176890] [adv loss: 2.677341] [time: 0:00:40.674896]\n",
            "261: [d_target loss: 0.277447] [d_source loss: 0.201785] [adv loss: 2.254621] [time: 0:00:40.795831]\n",
            "262: [d_target loss: 0.261565] [d_source loss: 0.209328] [adv loss: 2.587124] [time: 0:00:40.922313]\n",
            "263: [d_target loss: 0.248094] [d_source loss: 0.233147] [adv loss: 2.219307] [time: 0:00:41.051699]\n",
            "264: [d_target loss: 0.275181] [d_source loss: 0.208618] [adv loss: 2.815866] [time: 0:00:41.179381]\n",
            "265: [d_target loss: 0.248352] [d_source loss: 0.221055] [adv loss: 2.070409] [time: 0:00:41.298376]\n",
            "266: [d_target loss: 0.226369] [d_source loss: 0.187817] [adv loss: 2.755521] [time: 0:00:41.415744]\n",
            "267: [d_target loss: 0.207648] [d_source loss: 0.199563] [adv loss: 2.290595] [time: 0:00:41.536056]\n",
            "268: [d_target loss: 0.205543] [d_source loss: 0.239242] [adv loss: 2.643760] [time: 0:00:41.659927]\n",
            "269: [d_target loss: 0.218459] [d_source loss: 0.223786] [adv loss: 2.153362] [time: 0:00:41.781162]\n",
            "270: [d_target loss: 0.212377] [d_source loss: 0.188213] [adv loss: 2.523430] [time: 0:00:41.904682]\n",
            "271: [d_target loss: 0.220902] [d_source loss: 0.192436] [adv loss: 2.148524] [time: 0:00:42.027610]\n",
            "272: [d_target loss: 0.211215] [d_source loss: 0.214170] [adv loss: 2.662400] [time: 0:00:42.147269]\n",
            "273: [d_target loss: 0.216665] [d_source loss: 0.180541] [adv loss: 2.523197] [time: 0:00:42.272458]\n",
            "274: [d_target loss: 0.245738] [d_source loss: 0.196036] [adv loss: 2.456522] [time: 0:00:42.396354]\n",
            "275: [d_target loss: 0.194405] [d_source loss: 0.207453] [adv loss: 2.428033] [time: 0:00:42.514867]\n",
            "276: [d_target loss: 0.215980] [d_source loss: 0.208783] [adv loss: 2.569822] [time: 0:00:42.655715]\n",
            "277: [d_target loss: 0.222523] [d_source loss: 0.256928] [adv loss: 2.117817] [time: 0:00:42.775633]\n",
            "278: [d_target loss: 0.185860] [d_source loss: 0.209620] [adv loss: 2.410750] [time: 0:00:42.908930]\n",
            "279: [d_target loss: 0.346423] [d_source loss: 0.224095] [adv loss: 2.541173] [time: 0:00:43.031768]\n",
            "280: [d_target loss: 0.253270] [d_source loss: 0.201154] [adv loss: 2.292701] [time: 0:00:43.150448]\n",
            "281: [d_target loss: 0.242897] [d_source loss: 0.189374] [adv loss: 2.323748] [time: 0:00:43.272401]\n",
            "282: [d_target loss: 0.220827] [d_source loss: 0.172960] [adv loss: 2.629155] [time: 0:00:43.391560]\n",
            "283: [d_target loss: 0.247038] [d_source loss: 0.189833] [adv loss: 2.422817] [time: 0:00:43.515050]\n",
            "284: [d_target loss: 0.258212] [d_source loss: 0.180309] [adv loss: 2.738110] [time: 0:00:43.635827]\n",
            "285: [d_target loss: 0.224349] [d_source loss: 0.184580] [adv loss: 2.102423] [time: 0:00:43.753935]\n",
            "286: [d_target loss: 0.232708] [d_source loss: 0.187811] [adv loss: 2.822985] [time: 0:00:43.875182]\n",
            "287: [d_target loss: 0.236155] [d_source loss: 0.213454] [adv loss: 2.285287] [time: 0:00:43.993747]\n",
            "288: [d_target loss: 0.231377] [d_source loss: 0.168821] [adv loss: 2.758549] [time: 0:00:44.124820]\n",
            "289: [d_target loss: 0.190071] [d_source loss: 0.208228] [adv loss: 2.469670] [time: 0:00:44.241539]\n",
            "290: [d_target loss: 0.244152] [d_source loss: 0.191720] [adv loss: 2.503480] [time: 0:00:44.362849]\n",
            "291: [d_target loss: 0.216499] [d_source loss: 0.204362] [adv loss: 2.106801] [time: 0:00:44.481664]\n",
            "292: [d_target loss: 0.236687] [d_source loss: 0.194966] [adv loss: 2.873595] [time: 0:00:44.603976]\n",
            "293: [d_target loss: 0.256962] [d_source loss: 0.201753] [adv loss: 2.189579] [time: 0:00:44.971849]\n",
            "294: [d_target loss: 0.212729] [d_source loss: 0.193748] [adv loss: 2.659111] [time: 0:00:45.095376]\n",
            "295: [d_target loss: 0.219958] [d_source loss: 0.185807] [adv loss: 2.352827] [time: 0:00:45.211954]\n",
            "296: [d_target loss: 0.216401] [d_source loss: 0.184097] [adv loss: 2.499681] [time: 0:00:45.332848]\n",
            "297: [d_target loss: 0.195394] [d_source loss: 0.222588] [adv loss: 2.395360] [time: 0:00:45.455493]\n",
            "298: [d_target loss: 0.235058] [d_source loss: 0.182839] [adv loss: 2.707875] [time: 0:00:45.572376]\n",
            "299: [d_target loss: 0.181572] [d_source loss: 0.183600] [adv loss: 2.333547] [time: 0:00:45.691303]\n",
            "300: [d_target loss: 0.264062] [d_source loss: 0.176828] [adv loss: 2.768476] [time: 0:00:45.809563]\n",
            "301: [d_target loss: 0.226941] [d_source loss: 0.190835] [adv loss: 2.168792] [time: 0:00:45.930193]\n",
            "302: [d_target loss: 0.220195] [d_source loss: 0.189851] [adv loss: 2.628932] [time: 0:00:46.056781]\n",
            "303: [d_target loss: 0.183886] [d_source loss: 0.181006] [adv loss: 2.270456] [time: 0:00:46.179551]\n",
            "304: [d_target loss: 0.242693] [d_source loss: 0.185930] [adv loss: 2.841496] [time: 0:00:46.312147]\n",
            "305: [d_target loss: 0.238097] [d_source loss: 0.204176] [adv loss: 2.302394] [time: 0:00:46.439777]\n",
            "306: [d_target loss: 0.244493] [d_source loss: 0.185201] [adv loss: 2.379021] [time: 0:00:46.569343]\n",
            "307: [d_target loss: 0.254839] [d_source loss: 0.160379] [adv loss: 2.512373] [time: 0:00:46.696224]\n",
            "308: [d_target loss: 0.270972] [d_source loss: 0.167926] [adv loss: 2.548639] [time: 0:00:46.811057]\n",
            "309: [d_target loss: 0.220258] [d_source loss: 0.160898] [adv loss: 2.483641] [time: 0:00:46.931189]\n",
            "310: [d_target loss: 0.219945] [d_source loss: 0.183588] [adv loss: 2.637798] [time: 0:00:47.062031]\n",
            "311: [d_target loss: 0.211723] [d_source loss: 0.175445] [adv loss: 2.183389] [time: 0:00:47.203980]\n",
            "312: [d_target loss: 0.192303] [d_source loss: 0.217382] [adv loss: 2.797411] [time: 0:00:47.337152]\n",
            "313: [d_target loss: 0.224331] [d_source loss: 0.237738] [adv loss: 2.893862] [time: 0:00:47.473085]\n",
            "314: [d_target loss: 0.255179] [d_source loss: 0.214424] [adv loss: 2.500253] [time: 0:00:47.596155]\n",
            "315: [d_target loss: 0.232839] [d_source loss: 0.240961] [adv loss: 2.396324] [time: 0:00:47.716161]\n",
            "316: [d_target loss: 0.202846] [d_source loss: 0.216517] [adv loss: 2.435587] [time: 0:00:47.845223]\n",
            "317: [d_target loss: 0.253425] [d_source loss: 0.210311] [adv loss: 2.449305] [time: 0:00:47.964352]\n",
            "318: [d_target loss: 0.216439] [d_source loss: 0.176013] [adv loss: 2.613930] [time: 0:00:48.081360]\n",
            "319: [d_target loss: 0.203153] [d_source loss: 0.172374] [adv loss: 2.415443] [time: 0:00:48.195147]\n",
            "320: [d_target loss: 0.220830] [d_source loss: 0.179582] [adv loss: 2.479204] [time: 0:00:48.311580]\n",
            "321: [d_target loss: 0.209197] [d_source loss: 0.179427] [adv loss: 2.181859] [time: 0:00:48.428855]\n",
            "322: [d_target loss: 0.232460] [d_source loss: 0.189070] [adv loss: 2.952428] [time: 0:00:48.547371]\n",
            "323: [d_target loss: 0.221569] [d_source loss: 0.210949] [adv loss: 2.419605] [time: 0:00:48.666939]\n",
            "324: [d_target loss: 0.224604] [d_source loss: 0.207351] [adv loss: 2.575179] [time: 0:00:48.788101]\n",
            "325: [d_target loss: 0.211009] [d_source loss: 0.229002] [adv loss: 2.339403] [time: 0:00:48.903125]\n",
            "326: [d_target loss: 0.214297] [d_source loss: 0.165130] [adv loss: 2.620162] [time: 0:00:49.027647]\n",
            "327: [d_target loss: 0.202458] [d_source loss: 0.172408] [adv loss: 2.181789] [time: 0:00:49.157312]\n",
            "328: [d_target loss: 0.254588] [d_source loss: 0.189169] [adv loss: 2.863853] [time: 0:00:49.284408]\n",
            "329: [d_target loss: 0.242053] [d_source loss: 0.192401] [adv loss: 2.253846] [time: 0:00:49.412686]\n",
            "330: [d_target loss: 0.219662] [d_source loss: 0.182269] [adv loss: 2.514674] [time: 0:00:49.540168]\n",
            "331: [d_target loss: 0.227485] [d_source loss: 0.182854] [adv loss: 2.369983] [time: 0:00:49.675889]\n",
            "332: [d_target loss: 0.214425] [d_source loss: 0.187053] [adv loss: 2.417396] [time: 0:00:49.806728]\n",
            "333: [d_target loss: 0.251975] [d_source loss: 0.187732] [adv loss: 2.482921] [time: 0:00:49.937436]\n",
            "334: [d_target loss: 0.192836] [d_source loss: 0.181357] [adv loss: 2.790769] [time: 0:00:50.058939]\n",
            "335: [d_target loss: 0.202334] [d_source loss: 0.197985] [adv loss: 2.403381] [time: 0:00:50.195562]\n",
            "336: [d_target loss: 0.222275] [d_source loss: 0.251207] [adv loss: 2.744884] [time: 0:00:50.336065]\n",
            "337: [d_target loss: 0.238195] [d_source loss: 0.348169] [adv loss: 2.573689] [time: 0:00:50.468656]\n",
            "338: [d_target loss: 0.228390] [d_source loss: 0.150263] [adv loss: 2.417820] [time: 0:00:50.594857]\n",
            "339: [d_target loss: 0.225019] [d_source loss: 0.180276] [adv loss: 2.452497] [time: 0:00:50.717810]\n",
            "340: [d_target loss: 0.227522] [d_source loss: 0.154410] [adv loss: 2.490030] [time: 0:00:50.840069]\n",
            "341: [d_target loss: 0.221786] [d_source loss: 0.184535] [adv loss: 2.302307] [time: 0:00:50.959344]\n",
            "342: [d_target loss: 0.228867] [d_source loss: 0.144345] [adv loss: 2.754617] [time: 0:00:51.088970]\n",
            "343: [d_target loss: 0.251241] [d_source loss: 0.162345] [adv loss: 2.481635] [time: 0:00:51.225941]\n",
            "344: [d_target loss: 0.235166] [d_source loss: 0.167549] [adv loss: 2.407597] [time: 0:00:51.352815]\n",
            "345: [d_target loss: 0.193974] [d_source loss: 0.186133] [adv loss: 2.653103] [time: 0:00:51.496804]\n",
            "346: [d_target loss: 0.181012] [d_source loss: 0.207187] [adv loss: 2.532234] [time: 0:00:51.628441]\n",
            "347: [d_target loss: 0.203688] [d_source loss: 0.161349] [adv loss: 2.187232] [time: 0:00:51.746405]\n",
            "348: [d_target loss: 0.229179] [d_source loss: 0.192911] [adv loss: 2.591936] [time: 0:00:51.863960]\n",
            "349: [d_target loss: 0.273601] [d_source loss: 0.195291] [adv loss: 2.198982] [time: 0:00:51.977893]\n",
            "350: [d_target loss: 0.213368] [d_source loss: 0.187183] [adv loss: 2.215590] [time: 0:00:52.103065]\n",
            "351: [d_target loss: 0.209215] [d_source loss: 0.168586] [adv loss: 2.153753] [time: 0:00:52.231699]\n",
            "352: [d_target loss: 0.451923] [d_source loss: 0.232252] [adv loss: 3.057236] [time: 0:00:52.350655]\n",
            "353: [d_target loss: 0.207456] [d_source loss: 0.373780] [adv loss: 2.609558] [time: 0:00:52.470956]\n",
            "354: [d_target loss: 0.241997] [d_source loss: 0.241390] [adv loss: 2.644404] [time: 0:00:52.586525]\n",
            "355: [d_target loss: 0.242713] [d_source loss: 0.199960] [adv loss: 2.325871] [time: 0:00:52.717941]\n",
            "356: [d_target loss: 0.241781] [d_source loss: 0.186168] [adv loss: 2.622022] [time: 0:00:52.839100]\n",
            "357: [d_target loss: 0.298175] [d_source loss: 0.191250] [adv loss: 2.424544] [time: 0:00:52.967441]\n",
            "358: [d_target loss: 0.257291] [d_source loss: 0.186177] [adv loss: 2.430308] [time: 0:00:53.105593]\n",
            "359: [d_target loss: 0.194099] [d_source loss: 0.206295] [adv loss: 2.509862] [time: 0:00:53.232819]\n",
            "360: [d_target loss: 0.265489] [d_source loss: 0.219209] [adv loss: 2.874521] [time: 0:00:53.356890]\n",
            "361: [d_target loss: 0.218643] [d_source loss: 0.253134] [adv loss: 2.297955] [time: 0:00:53.472657]\n",
            "362: [d_target loss: 0.199885] [d_source loss: 0.168846] [adv loss: 2.593969] [time: 0:00:53.590851]\n",
            "363: [d_target loss: 0.193564] [d_source loss: 0.161933] [adv loss: 2.384775] [time: 0:00:53.707646]\n",
            "364: [d_target loss: 0.185508] [d_source loss: 0.159444] [adv loss: 2.513921] [time: 0:00:53.832713]\n",
            "365: [d_target loss: 0.219751] [d_source loss: 0.189709] [adv loss: 2.592552] [time: 0:00:53.954276]\n",
            "366: [d_target loss: 0.201531] [d_source loss: 0.174068] [adv loss: 2.345116] [time: 0:00:54.072295]\n",
            "367: [d_target loss: 0.205601] [d_source loss: 0.185461] [adv loss: 2.784173] [time: 0:00:54.202133]\n",
            "368: [d_target loss: 0.202493] [d_source loss: 0.176727] [adv loss: 2.160498] [time: 0:00:54.320410]\n",
            "369: [d_target loss: 0.219700] [d_source loss: 0.170652] [adv loss: 2.636887] [time: 0:00:54.442102]\n",
            "370: [d_target loss: 0.222331] [d_source loss: 0.192523] [adv loss: 2.209968] [time: 0:00:54.561114]\n",
            "371: [d_target loss: 0.182987] [d_source loss: 0.218142] [adv loss: 2.799183] [time: 0:00:54.679306]\n",
            "372: [d_target loss: 0.219401] [d_source loss: 0.262936] [adv loss: 2.059708] [time: 0:00:54.796533]\n",
            "373: [d_target loss: 0.189743] [d_source loss: 0.175571] [adv loss: 2.867681] [time: 0:00:54.911781]\n",
            "374: [d_target loss: 0.209163] [d_source loss: 0.211482] [adv loss: 2.162658] [time: 0:00:55.040335]\n",
            "375: [d_target loss: 0.373901] [d_source loss: 0.165420] [adv loss: 2.544573] [time: 0:00:55.175626]\n",
            "376: [d_target loss: 0.242969] [d_source loss: 0.205034] [adv loss: 2.375227] [time: 0:00:55.292406]\n",
            "377: [d_target loss: 0.228457] [d_source loss: 0.174915] [adv loss: 2.596630] [time: 0:00:55.409372]\n",
            "378: [d_target loss: 0.230088] [d_source loss: 0.196876] [adv loss: 2.157567] [time: 0:00:55.528219]\n",
            "379: [d_target loss: 0.219390] [d_source loss: 0.185766] [adv loss: 2.572478] [time: 0:00:55.658844]\n",
            "380: [d_target loss: 0.254931] [d_source loss: 0.189509] [adv loss: 1.981731] [time: 0:00:55.776874]\n",
            "381: [d_target loss: 0.228567] [d_source loss: 0.197171] [adv loss: 2.710039] [time: 0:00:55.895473]\n",
            "382: [d_target loss: 0.199973] [d_source loss: 0.228867] [adv loss: 2.437848] [time: 0:00:56.013310]\n",
            "383: [d_target loss: 0.221685] [d_source loss: 0.209710] [adv loss: 2.867366] [time: 0:00:56.133317]\n",
            "384: [d_target loss: 0.192046] [d_source loss: 0.245138] [adv loss: 2.486042] [time: 0:00:56.258233]\n",
            "385: [d_target loss: 0.184951] [d_source loss: 0.175900] [adv loss: 2.578858] [time: 0:00:56.378161]\n",
            "386: [d_target loss: 0.188012] [d_source loss: 0.164076] [adv loss: 2.629275] [time: 0:00:56.494870]\n",
            "387: [d_target loss: 0.223090] [d_source loss: 0.209602] [adv loss: 2.601675] [time: 0:00:56.620564]\n",
            "388: [d_target loss: 0.207210] [d_source loss: 0.227102] [adv loss: 2.394312] [time: 0:00:56.742896]\n",
            "389: [d_target loss: 0.342917] [d_source loss: 0.177440] [adv loss: 2.535986] [time: 0:00:56.861378]\n",
            "390: [d_target loss: 0.232458] [d_source loss: 0.184747] [adv loss: 2.653583] [time: 0:00:56.982703]\n",
            "391: [d_target loss: 0.241312] [d_source loss: 0.208924] [adv loss: 2.779002] [time: 0:00:57.101763]\n",
            "392: [d_target loss: 0.244313] [d_source loss: 0.226620] [adv loss: 2.332774] [time: 0:00:57.225321]\n",
            "393: [d_target loss: 0.191947] [d_source loss: 0.168467] [adv loss: 2.907115] [time: 0:00:57.349120]\n",
            "394: [d_target loss: 0.206580] [d_source loss: 0.187137] [adv loss: 2.183175] [time: 0:00:57.469398]\n",
            "395: [d_target loss: 0.383877] [d_source loss: 0.186333] [adv loss: 3.107865] [time: 0:00:57.585963]\n",
            "396: [d_target loss: 0.266107] [d_source loss: 0.176641] [adv loss: 2.249640] [time: 0:00:57.701659]\n",
            "397: [d_target loss: 0.233606] [d_source loss: 0.221328] [adv loss: 2.547116] [time: 0:00:57.817617]\n",
            "398: [d_target loss: 0.227079] [d_source loss: 0.254994] [adv loss: 2.233760] [time: 0:00:57.939681]\n",
            "399: [d_target loss: 0.214586] [d_source loss: 0.200306] [adv loss: 2.572290] [time: 0:00:58.061326]\n",
            "400: [d_target loss: 0.208435] [d_source loss: 0.180419] [adv loss: 2.330415] [time: 0:00:58.184889]\n",
            "401: [d_target loss: 0.200300] [d_source loss: 0.209595] [adv loss: 2.517147] [time: 0:00:58.304380]\n",
            "402: [d_target loss: 0.218422] [d_source loss: 0.169937] [adv loss: 2.288454] [time: 0:00:58.421411]\n",
            "403: [d_target loss: 0.185347] [d_source loss: 0.169090] [adv loss: 2.676364] [time: 0:00:58.546422]\n",
            "404: [d_target loss: 0.229884] [d_source loss: 0.171485] [adv loss: 2.589961] [time: 0:00:58.665983]\n",
            "405: [d_target loss: 0.192337] [d_source loss: 0.169726] [adv loss: 2.654138] [time: 0:00:58.796081]\n",
            "406: [d_target loss: 0.194221] [d_source loss: 0.187959] [adv loss: 2.339952] [time: 0:00:58.922185]\n",
            "407: [d_target loss: 0.225194] [d_source loss: 0.198872] [adv loss: 2.359744] [time: 0:00:59.049415]\n",
            "408: [d_target loss: 0.219828] [d_source loss: 0.165915] [adv loss: 2.282108] [time: 0:00:59.182998]\n",
            "409: [d_target loss: 0.195796] [d_source loss: 0.191501] [adv loss: 2.760585] [time: 0:00:59.322888]\n",
            "410: [d_target loss: 0.202683] [d_source loss: 0.156695] [adv loss: 2.448789] [time: 0:00:59.448719]\n",
            "411: [d_target loss: 0.206876] [d_source loss: 0.201377] [adv loss: 2.728489] [time: 0:00:59.572806]\n",
            "412: [d_target loss: 0.205314] [d_source loss: 0.201467] [adv loss: 2.174933] [time: 0:00:59.704802]\n",
            "413: [d_target loss: 0.349447] [d_source loss: 0.173710] [adv loss: 2.992328] [time: 0:00:59.832876]\n",
            "414: [d_target loss: 0.262182] [d_source loss: 0.249766] [adv loss: 2.219692] [time: 0:00:59.961706]\n",
            "415: [d_target loss: 0.234494] [d_source loss: 0.207217] [adv loss: 2.548888] [time: 0:01:00.079984]\n",
            "416: [d_target loss: 0.242709] [d_source loss: 0.234734] [adv loss: 2.181971] [time: 0:01:00.210531]\n",
            "417: [d_target loss: 0.240722] [d_source loss: 0.189577] [adv loss: 2.415484] [time: 0:01:00.347279]\n",
            "418: [d_target loss: 0.222321] [d_source loss: 0.173617] [adv loss: 2.540809] [time: 0:01:00.484271]\n",
            "419: [d_target loss: 0.213114] [d_source loss: 0.182341] [adv loss: 2.649798] [time: 0:01:00.614511]\n",
            "420: [d_target loss: 0.214860] [d_source loss: 0.207946] [adv loss: 2.224699] [time: 0:01:00.734716]\n",
            "421: [d_target loss: 0.177866] [d_source loss: 0.193257] [adv loss: 2.618388] [time: 0:01:00.850855]\n",
            "422: [d_target loss: 0.213661] [d_source loss: 0.171934] [adv loss: 2.175348] [time: 0:01:00.975167]\n",
            "423: [d_target loss: 0.237260] [d_source loss: 0.202871] [adv loss: 2.834092] [time: 0:01:01.096201]\n",
            "424: [d_target loss: 0.190472] [d_source loss: 0.235987] [adv loss: 2.404370] [time: 0:01:01.219985]\n",
            "425: [d_target loss: 0.214447] [d_source loss: 0.171254] [adv loss: 2.456263] [time: 0:01:01.334323]\n",
            "426: [d_target loss: 0.201894] [d_source loss: 0.169665] [adv loss: 2.656678] [time: 0:01:01.448394]\n",
            "427: [d_target loss: 0.223117] [d_source loss: 0.209142] [adv loss: 2.625855] [time: 0:01:01.576609]\n",
            "428: [d_target loss: 0.205617] [d_source loss: 0.185976] [adv loss: 2.424381] [time: 0:01:01.695913]\n",
            "429: [d_target loss: 0.224967] [d_source loss: 0.183429] [adv loss: 2.395432] [time: 0:01:01.812557]\n",
            "430: [d_target loss: 0.249633] [d_source loss: 0.170278] [adv loss: 2.612960] [time: 0:01:01.932004]\n",
            "431: [d_target loss: 0.214325] [d_source loss: 0.185620] [adv loss: 2.827001] [time: 0:01:02.046205]\n",
            "432: [d_target loss: 0.197378] [d_source loss: 0.217415] [adv loss: 2.337551] [time: 0:01:02.183994]\n",
            "433: [d_target loss: 0.212908] [d_source loss: 0.187731] [adv loss: 2.687779] [time: 0:01:02.323447]\n",
            "434: [d_target loss: 0.177375] [d_source loss: 0.206800] [adv loss: 2.198881] [time: 0:01:02.449701]\n",
            "435: [d_target loss: 0.268645] [d_source loss: 0.185212] [adv loss: 2.800333] [time: 0:01:02.586016]\n",
            "436: [d_target loss: 0.228314] [d_source loss: 0.178570] [adv loss: 2.239330] [time: 0:01:02.710019]\n",
            "437: [d_target loss: 0.249302] [d_source loss: 0.142936] [adv loss: 2.677844] [time: 0:01:02.829270]\n",
            "438: [d_target loss: 0.255691] [d_source loss: 0.184372] [adv loss: 2.314193] [time: 0:01:02.951666]\n",
            "439: [d_target loss: 0.235996] [d_source loss: 0.145181] [adv loss: 2.699148] [time: 0:01:03.087358]\n",
            "440: [d_target loss: 0.231702] [d_source loss: 0.197671] [adv loss: 2.290756] [time: 0:01:03.211710]\n",
            "441: [d_target loss: 0.259112] [d_source loss: 0.188079] [adv loss: 2.568878] [time: 0:01:03.346779]\n",
            "442: [d_target loss: 0.236977] [d_source loss: 0.209622] [adv loss: 2.329881] [time: 0:01:03.464407]\n",
            "443: [d_target loss: 0.214666] [d_source loss: 0.205374] [adv loss: 2.614293] [time: 0:01:03.580838]\n",
            "444: [d_target loss: 0.176706] [d_source loss: 0.198302] [adv loss: 2.408713] [time: 0:01:03.702147]\n",
            "445: [d_target loss: 0.181672] [d_source loss: 0.204081] [adv loss: 2.692170] [time: 0:01:03.819813]\n",
            "446: [d_target loss: 0.197359] [d_source loss: 0.208063] [adv loss: 2.240748] [time: 0:01:03.942865]\n",
            "447: [d_target loss: 0.214490] [d_source loss: 0.172219] [adv loss: 2.430585] [time: 0:01:04.061256]\n",
            "448: [d_target loss: 0.192223] [d_source loss: 0.187586] [adv loss: 2.269039] [time: 0:01:04.182557]\n",
            "449: [d_target loss: 0.200432] [d_source loss: 0.225634] [adv loss: 2.521737] [time: 0:01:04.305597]\n",
            "450: [d_target loss: 0.238523] [d_source loss: 0.179281] [adv loss: 2.449914] [time: 0:01:04.427931]\n",
            "451: [d_target loss: 0.205779] [d_source loss: 0.172155] [adv loss: 2.540817] [time: 0:01:04.551584]\n",
            "452: [d_target loss: 0.219429] [d_source loss: 0.194361] [adv loss: 2.394428] [time: 0:01:04.669945]\n",
            "453: [d_target loss: 0.208960] [d_source loss: 0.179134] [adv loss: 2.681295] [time: 0:01:04.791154]\n",
            "454: [d_target loss: 0.193895] [d_source loss: 0.220140] [adv loss: 2.238709] [time: 0:01:04.912830]\n",
            "455: [d_target loss: 0.204092] [d_source loss: 0.193367] [adv loss: 2.608700] [time: 0:01:05.026016]\n",
            "456: [d_target loss: 0.205782] [d_source loss: 0.199409] [adv loss: 2.346136] [time: 0:01:05.150704]\n",
            "457: [d_target loss: 0.171554] [d_source loss: 0.197355] [adv loss: 2.742623] [time: 0:01:05.286556]\n",
            "458: [d_target loss: 0.194835] [d_source loss: 0.212033] [adv loss: 2.166549] [time: 0:01:05.418083]\n",
            "459: [d_target loss: 0.198019] [d_source loss: 0.184595] [adv loss: 2.619765] [time: 0:01:05.551606]\n",
            "460: [d_target loss: 0.175081] [d_source loss: 0.186894] [adv loss: 2.209430] [time: 0:01:05.676694]\n",
            "461: [d_target loss: 0.213107] [d_source loss: 0.203765] [adv loss: 2.872309] [time: 0:01:05.801471]\n",
            "462: [d_target loss: 0.232663] [d_source loss: 0.213813] [adv loss: 2.463281] [time: 0:01:05.922012]\n",
            "463: [d_target loss: 0.238012] [d_source loss: 0.219889] [adv loss: 2.669939] [time: 0:01:06.042836]\n",
            "464: [d_target loss: 0.191256] [d_source loss: 0.203026] [adv loss: 2.513331] [time: 0:01:06.162725]\n",
            "465: [d_target loss: 0.190846] [d_source loss: 0.187080] [adv loss: 2.991036] [time: 0:01:06.294039]\n",
            "466: [d_target loss: 0.170030] [d_source loss: 0.209300] [adv loss: 2.531888] [time: 0:01:06.415651]\n",
            "467: [d_target loss: 0.299670] [d_source loss: 0.212753] [adv loss: 2.974845] [time: 0:01:06.534717]\n",
            "468: [d_target loss: 0.289530] [d_source loss: 0.207825] [adv loss: 2.337793] [time: 0:01:06.657487]\n",
            "469: [d_target loss: 0.254477] [d_source loss: 0.163197] [adv loss: 2.526925] [time: 0:01:06.774037]\n",
            "470: [d_target loss: 0.234237] [d_source loss: 0.190687] [adv loss: 2.295666] [time: 0:01:06.904991]\n",
            "471: [d_target loss: 0.214342] [d_source loss: 0.160359] [adv loss: 2.710720] [time: 0:01:07.028647]\n",
            "472: [d_target loss: 0.226228] [d_source loss: 0.170858] [adv loss: 2.068523] [time: 0:01:07.147605]\n",
            "473: [d_target loss: 0.235523] [d_source loss: 0.210160] [adv loss: 2.720827] [time: 0:01:07.276261]\n",
            "474: [d_target loss: 0.226766] [d_source loss: 0.188831] [adv loss: 2.160826] [time: 0:01:07.408590]\n",
            "475: [d_target loss: 0.201382] [d_source loss: 0.233430] [adv loss: 2.750413] [time: 0:01:07.545820]\n",
            "476: [d_target loss: 0.196729] [d_source loss: 0.206294] [adv loss: 2.388788] [time: 0:01:07.665235]\n",
            "477: [d_target loss: 0.199955] [d_source loss: 0.222436] [adv loss: 2.613225] [time: 0:01:07.785480]\n",
            "478: [d_target loss: 0.270517] [d_source loss: 0.199439] [adv loss: 2.590918] [time: 0:01:07.901893]\n",
            "479: [d_target loss: 0.217218] [d_source loss: 0.186399] [adv loss: 2.804140] [time: 0:01:08.018748]\n",
            "480: [d_target loss: 0.222857] [d_source loss: 0.176019] [adv loss: 2.686436] [time: 0:01:08.145307]\n",
            "481: [d_target loss: 0.184870] [d_source loss: 0.177065] [adv loss: 2.646145] [time: 0:01:08.273622]\n",
            "482: [d_target loss: 0.213075] [d_source loss: 0.177201] [adv loss: 2.503103] [time: 0:01:08.397469]\n",
            "483: [d_target loss: 0.208324] [d_source loss: 0.181944] [adv loss: 2.742945] [time: 0:01:08.517575]\n",
            "484: [d_target loss: 0.195419] [d_source loss: 0.203105] [adv loss: 2.245219] [time: 0:01:08.641572]\n",
            "485: [d_target loss: 0.187539] [d_source loss: 0.204402] [adv loss: 2.577556] [time: 0:01:08.763042]\n",
            "486: [d_target loss: 0.227219] [d_source loss: 0.197815] [adv loss: 2.712183] [time: 0:01:08.879948]\n",
            "487: [d_target loss: 0.219076] [d_source loss: 0.181130] [adv loss: 2.611454] [time: 0:01:08.998520]\n",
            "488: [d_target loss: 0.174753] [d_source loss: 0.218517] [adv loss: 2.236360] [time: 0:01:09.118688]\n",
            "489: [d_target loss: 0.204216] [d_source loss: 0.176689] [adv loss: 2.606200] [time: 0:01:09.243475]\n",
            "490: [d_target loss: 0.202497] [d_source loss: 0.196582] [adv loss: 2.236015] [time: 0:01:09.369447]\n",
            "491: [d_target loss: 0.249269] [d_source loss: 0.195701] [adv loss: 2.381168] [time: 0:01:09.487399]\n",
            "492: [d_target loss: 0.207932] [d_source loss: 0.179303] [adv loss: 2.224915] [time: 0:01:09.604240]\n",
            "493: [d_target loss: 0.200413] [d_source loss: 0.208597] [adv loss: 3.038329] [time: 0:01:09.721157]\n",
            "494: [d_target loss: 0.184233] [d_source loss: 0.266140] [adv loss: 2.346091] [time: 0:01:09.844000]\n",
            "495: [d_target loss: 0.200406] [d_source loss: 0.184168] [adv loss: 2.604633] [time: 0:01:09.964996]\n",
            "496: [d_target loss: 0.180498] [d_source loss: 0.182910] [adv loss: 2.431200] [time: 0:01:10.085863]\n",
            "497: [d_target loss: 0.170686] [d_source loss: 0.188528] [adv loss: 2.801256] [time: 0:01:10.211502]\n",
            "498: [d_target loss: 0.212234] [d_source loss: 0.195316] [adv loss: 2.335407] [time: 0:01:10.333993]\n",
            "499: [d_target loss: 0.204388] [d_source loss: 0.179563] [adv loss: 2.323391] [time: 0:01:10.462503]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXRxOwenVXHX"
      },
      "source": [
        "parser = argparse.ArgumentParser()\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "# load pre-trained mnist-svhn source & target generators\r\n",
        "if args.mnist_svhn_g_source:\r\n",
        "    g_source = load_model(args.mnist_svhn_g_source)\r\n",
        "    if args.mnist_svhn_g_target:\r\n",
        "        g_target = load_model(args.mnist_svhn_g_target)\r\n",
        "        g_models = (g_source, g_target)\r\n",
        "        mnist_cross_svhn(g_models)\r\n",
        "# train a mnist-svhn CycleGAN\r\n",
        "else:\r\n",
        "    mnist_cross_svhn()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
