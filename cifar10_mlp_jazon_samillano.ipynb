{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mlp_cifar10.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMkIUyXLLYkY5g2W85mw9Ag"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eE9NLsc3gsSC"},"source":["# MLP CIFAR10\n","\n","Jazon Samillano"]},{"cell_type":"code","metadata":{"id":"I48dSZOALkpj"},"source":["import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.callbacks import ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IQxUBKknQ5Y","executionInfo":{"status":"ok","timestamp":1602227797703,"user_tz":240,"elapsed":17078,"user":{"displayName":"Jazon Samillano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38FD5jYw0f-Aq4w9GYw6VLsoIdOlo8btjIQwQ=s64","userId":"00135806175043031109"}},"outputId":"14cb07cb-81e0-4388-efd1-426260746290","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()  # Load cifar10 dataset"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z42MhwS5nOA3"},"source":["# Compute the number of labels.\n","num_labels = len(np.unique(y_train))\n","\n","# Convert to one-hot vector.\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# Image dimensions (assumed square)\n","image_size = x_train.shape[1]\n","input_size = image_size * image_size * 3\n","\n","# Resize and normalize.\n","x_train = np.reshape(x_train, [-1, input_size])\n","x_train = x_train.astype('float32') / 255\n","x_test = np.reshape(x_test, [-1, input_size])\n","x_test = x_test.astype('float32') / 255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ldJrtOjnJne","executionInfo":{"status":"ok","timestamp":1602228183034,"user_tz":240,"elapsed":163815,"user":{"displayName":"Jazon Samillano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38FD5jYw0f-Aq4w9GYw6VLsoIdOlo8btjIQwQ=s64","userId":"00135806175043031109"}},"outputId":"94b2e2a5-e132-4243-fec3-fc23487702f5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Network parameters.\n","batch_size = 128\n","dropout = 0.15\n","\n","# Model is a 4-layer MLP with ReLU and dropout after each layer.\n","model = Sequential()\n","model.add(Dense(1024, input_dim=input_size))\n","model.add(Activation('relu'))\n","model.add(Dropout(dropout))\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(dropout))\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(dropout))\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(dropout))\n","model.add(Dense(num_labels))\n","model.add(Activation('softmax'))  # Output for one-hot vector\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',                               # Loss function for one-hot vector\n","              optimizer=keras.optimizers.RMSprop(lr=0.0001, decay=1e-6),     # RMSprop optimizer\n","              metrics=['accuracy'])                                          # Accuracy is good metric for classification tasks.\n","\n","early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)  # Early stop if no longer improving\n","filepath = 'mlp-cifar10-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')  # Checkpoint\n","\n","history = model.fit(x_train, y_train, epochs=200, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=[early_stop, checkpoint])\n","\n","# Validate the model on test dataset to determine generalization.\n","_, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n","print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_10 (Dense)             (None, 1024)              3146752   \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 1024)              0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 512)               524800    \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 64)                32832     \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 64)                4160      \n","_________________________________________________________________\n","activation_13 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 10)                650       \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 3,709,194\n","Trainable params: 3,709,194\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/200\n","308/313 [============================>.] - ETA: 0s - loss: 2.1253 - accuracy: 0.2211\n","Epoch 00001: val_accuracy improved from -inf to 0.30780, saving model to weights-improvement-01-0.31.hdf5\n","313/313 [==============================] - 2s 6ms/step - loss: 2.1235 - accuracy: 0.2216 - val_loss: 1.9365 - val_accuracy: 0.3078\n","Epoch 2/200\n","302/313 [===========================>..] - ETA: 0s - loss: 1.9328 - accuracy: 0.3035\n","Epoch 00002: val_accuracy improved from 0.30780 to 0.37230, saving model to weights-improvement-02-0.37.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.9314 - accuracy: 0.3043 - val_loss: 1.7991 - val_accuracy: 0.3723\n","Epoch 3/200\n","312/313 [============================>.] - ETA: 0s - loss: 1.8487 - accuracy: 0.3353\n","Epoch 00003: val_accuracy did not improve from 0.37230\n","313/313 [==============================] - 2s 5ms/step - loss: 1.8489 - accuracy: 0.3352 - val_loss: 1.8018 - val_accuracy: 0.3622\n","Epoch 4/200\n","307/313 [============================>.] - ETA: 0s - loss: 1.7919 - accuracy: 0.3585\n","Epoch 00004: val_accuracy improved from 0.37230 to 0.37730, saving model to weights-improvement-04-0.38.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.7917 - accuracy: 0.3587 - val_loss: 1.7364 - val_accuracy: 0.3773\n","Epoch 5/200\n","312/313 [============================>.] - ETA: 0s - loss: 1.7498 - accuracy: 0.3760\n","Epoch 00005: val_accuracy improved from 0.37730 to 0.38700, saving model to weights-improvement-05-0.39.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.7500 - accuracy: 0.3760 - val_loss: 1.7177 - val_accuracy: 0.3870\n","Epoch 6/200\n","308/313 [============================>.] - ETA: 0s - loss: 1.7063 - accuracy: 0.3939\n","Epoch 00006: val_accuracy improved from 0.38700 to 0.40100, saving model to weights-improvement-06-0.40.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.7056 - accuracy: 0.3943 - val_loss: 1.6829 - val_accuracy: 0.4010\n","Epoch 7/200\n","306/313 [============================>.] - ETA: 0s - loss: 1.6713 - accuracy: 0.4054\n","Epoch 00007: val_accuracy improved from 0.40100 to 0.41030, saving model to weights-improvement-07-0.41.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.6720 - accuracy: 0.4055 - val_loss: 1.6392 - val_accuracy: 0.4103\n","Epoch 8/200\n","310/313 [============================>.] - ETA: 0s - loss: 1.6428 - accuracy: 0.4193\n","Epoch 00008: val_accuracy improved from 0.41030 to 0.42220, saving model to weights-improvement-08-0.42.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.6431 - accuracy: 0.4192 - val_loss: 1.6356 - val_accuracy: 0.4222\n","Epoch 9/200\n","313/313 [==============================] - ETA: 0s - loss: 1.6212 - accuracy: 0.4257\n","Epoch 00009: val_accuracy did not improve from 0.42220\n","313/313 [==============================] - 2s 5ms/step - loss: 1.6212 - accuracy: 0.4257 - val_loss: 1.6613 - val_accuracy: 0.4011\n","Epoch 10/200\n","303/313 [============================>.] - ETA: 0s - loss: 1.6005 - accuracy: 0.4316\n","Epoch 00010: val_accuracy improved from 0.42220 to 0.43780, saving model to weights-improvement-10-0.44.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.6009 - accuracy: 0.4319 - val_loss: 1.5824 - val_accuracy: 0.4378\n","Epoch 11/200\n","310/313 [============================>.] - ETA: 0s - loss: 1.5736 - accuracy: 0.4433\n","Epoch 00011: val_accuracy improved from 0.43780 to 0.45020, saving model to weights-improvement-11-0.45.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.5739 - accuracy: 0.4436 - val_loss: 1.5394 - val_accuracy: 0.4502\n","Epoch 12/200\n","309/313 [============================>.] - ETA: 0s - loss: 1.5575 - accuracy: 0.4495\n","Epoch 00012: val_accuracy improved from 0.45020 to 0.46780, saving model to weights-improvement-12-0.47.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.5574 - accuracy: 0.4496 - val_loss: 1.5102 - val_accuracy: 0.4678\n","Epoch 13/200\n","311/313 [============================>.] - ETA: 0s - loss: 1.5345 - accuracy: 0.4560\n","Epoch 00013: val_accuracy did not improve from 0.46780\n","313/313 [==============================] - 2s 5ms/step - loss: 1.5344 - accuracy: 0.4561 - val_loss: 1.5132 - val_accuracy: 0.4635\n","Epoch 14/200\n","303/313 [============================>.] - ETA: 0s - loss: 1.5256 - accuracy: 0.4594\n","Epoch 00014: val_accuracy did not improve from 0.46780\n","313/313 [==============================] - 2s 5ms/step - loss: 1.5245 - accuracy: 0.4600 - val_loss: 1.6059 - val_accuracy: 0.4334\n","Epoch 15/200\n","313/313 [==============================] - ETA: 0s - loss: 1.5029 - accuracy: 0.4697\n","Epoch 00015: val_accuracy improved from 0.46780 to 0.47970, saving model to weights-improvement-15-0.48.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.5029 - accuracy: 0.4697 - val_loss: 1.4699 - val_accuracy: 0.4797\n","Epoch 16/200\n","302/313 [===========================>..] - ETA: 0s - loss: 1.4853 - accuracy: 0.4740\n","Epoch 00016: val_accuracy did not improve from 0.47970\n","313/313 [==============================] - 2s 5ms/step - loss: 1.4867 - accuracy: 0.4738 - val_loss: 1.5156 - val_accuracy: 0.4654\n","Epoch 17/200\n","306/313 [============================>.] - ETA: 0s - loss: 1.4624 - accuracy: 0.4838\n","Epoch 00017: val_accuracy did not improve from 0.47970\n","313/313 [==============================] - 2s 5ms/step - loss: 1.4641 - accuracy: 0.4837 - val_loss: 1.5478 - val_accuracy: 0.4520\n","Epoch 18/200\n","305/313 [============================>.] - ETA: 0s - loss: 1.4536 - accuracy: 0.4827\n","Epoch 00018: val_accuracy improved from 0.47970 to 0.48210, saving model to weights-improvement-18-0.48.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.4541 - accuracy: 0.4827 - val_loss: 1.4866 - val_accuracy: 0.4821\n","Epoch 19/200\n","304/313 [============================>.] - ETA: 0s - loss: 1.4368 - accuracy: 0.4930\n","Epoch 00019: val_accuracy improved from 0.48210 to 0.48270, saving model to weights-improvement-19-0.48.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.4388 - accuracy: 0.4923 - val_loss: 1.4641 - val_accuracy: 0.4827\n","Epoch 20/200\n","303/313 [============================>.] - ETA: 0s - loss: 1.4163 - accuracy: 0.5017\n","Epoch 00020: val_accuracy improved from 0.48270 to 0.48690, saving model to weights-improvement-20-0.49.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.4177 - accuracy: 0.5014 - val_loss: 1.4647 - val_accuracy: 0.4869\n","Epoch 21/200\n","304/313 [============================>.] - ETA: 0s - loss: 1.4066 - accuracy: 0.5051\n","Epoch 00021: val_accuracy did not improve from 0.48690\n","313/313 [==============================] - 2s 5ms/step - loss: 1.4065 - accuracy: 0.5051 - val_loss: 1.5394 - val_accuracy: 0.4635\n","Epoch 22/200\n","304/313 [============================>.] - ETA: 0s - loss: 1.3917 - accuracy: 0.5086\n","Epoch 00022: val_accuracy did not improve from 0.48690\n","313/313 [==============================] - 2s 5ms/step - loss: 1.3920 - accuracy: 0.5091 - val_loss: 1.4669 - val_accuracy: 0.4842\n","Epoch 23/200\n","313/313 [==============================] - ETA: 0s - loss: 1.3793 - accuracy: 0.5132\n","Epoch 00023: val_accuracy improved from 0.48690 to 0.51030, saving model to weights-improvement-23-0.51.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.3793 - accuracy: 0.5132 - val_loss: 1.4006 - val_accuracy: 0.5103\n","Epoch 24/200\n","303/313 [============================>.] - ETA: 0s - loss: 1.3673 - accuracy: 0.5198\n","Epoch 00024: val_accuracy improved from 0.51030 to 0.51310, saving model to weights-improvement-24-0.51.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.3683 - accuracy: 0.5193 - val_loss: 1.3824 - val_accuracy: 0.5131\n","Epoch 25/200\n","306/313 [============================>.] - ETA: 0s - loss: 1.3476 - accuracy: 0.5218\n","Epoch 00025: val_accuracy did not improve from 0.51310\n","313/313 [==============================] - 2s 5ms/step - loss: 1.3477 - accuracy: 0.5217 - val_loss: 1.4095 - val_accuracy: 0.4972\n","Epoch 26/200\n","310/313 [============================>.] - ETA: 0s - loss: 1.3357 - accuracy: 0.5265\n","Epoch 00026: val_accuracy did not improve from 0.51310\n","313/313 [==============================] - 2s 5ms/step - loss: 1.3343 - accuracy: 0.5270 - val_loss: 1.4795 - val_accuracy: 0.4884\n","Epoch 27/200\n","302/313 [===========================>..] - ETA: 0s - loss: 1.3250 - accuracy: 0.5323\n","Epoch 00027: val_accuracy did not improve from 0.51310\n","313/313 [==============================] - 2s 5ms/step - loss: 1.3250 - accuracy: 0.5321 - val_loss: 1.4882 - val_accuracy: 0.4751\n","Epoch 28/200\n","313/313 [==============================] - ETA: 0s - loss: 1.3063 - accuracy: 0.5363\n","Epoch 00028: val_accuracy did not improve from 0.51310\n","313/313 [==============================] - 2s 5ms/step - loss: 1.3063 - accuracy: 0.5363 - val_loss: 1.4883 - val_accuracy: 0.4876\n","Epoch 29/200\n","303/313 [============================>.] - ETA: 0s - loss: 1.2957 - accuracy: 0.5422\n","Epoch 00029: val_accuracy improved from 0.51310 to 0.51540, saving model to weights-improvement-29-0.52.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.2956 - accuracy: 0.5423 - val_loss: 1.3865 - val_accuracy: 0.5154\n","Epoch 30/200\n","313/313 [==============================] - ETA: 0s - loss: 1.2864 - accuracy: 0.5441\n","Epoch 00030: val_accuracy did not improve from 0.51540\n","313/313 [==============================] - 2s 5ms/step - loss: 1.2864 - accuracy: 0.5441 - val_loss: 1.3984 - val_accuracy: 0.5025\n","Epoch 31/200\n","311/313 [============================>.] - ETA: 0s - loss: 1.2722 - accuracy: 0.5487\n","Epoch 00031: val_accuracy improved from 0.51540 to 0.52550, saving model to weights-improvement-31-0.53.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.2721 - accuracy: 0.5487 - val_loss: 1.3654 - val_accuracy: 0.5255\n","Epoch 32/200\n","313/313 [==============================] - ETA: 0s - loss: 1.2610 - accuracy: 0.5563\n","Epoch 00032: val_accuracy did not improve from 0.52550\n","313/313 [==============================] - 2s 5ms/step - loss: 1.2610 - accuracy: 0.5563 - val_loss: 1.4352 - val_accuracy: 0.5016\n","Epoch 33/200\n","307/313 [============================>.] - ETA: 0s - loss: 1.2487 - accuracy: 0.5591\n","Epoch 00033: val_accuracy did not improve from 0.52550\n","313/313 [==============================] - 2s 5ms/step - loss: 1.2475 - accuracy: 0.5598 - val_loss: 1.4555 - val_accuracy: 0.5019\n","Epoch 34/200\n","307/313 [============================>.] - ETA: 0s - loss: 1.2369 - accuracy: 0.5651\n","Epoch 00034: val_accuracy did not improve from 0.52550\n","313/313 [==============================] - 2s 5ms/step - loss: 1.2367 - accuracy: 0.5653 - val_loss: 1.3884 - val_accuracy: 0.5212\n","Epoch 35/200\n","306/313 [============================>.] - ETA: 0s - loss: 1.2233 - accuracy: 0.5685\n","Epoch 00035: val_accuracy did not improve from 0.52550\n","313/313 [==============================] - 2s 6ms/step - loss: 1.2230 - accuracy: 0.5689 - val_loss: 1.3592 - val_accuracy: 0.5248\n","Epoch 36/200\n","312/313 [============================>.] - ETA: 0s - loss: 1.2144 - accuracy: 0.5712\n","Epoch 00036: val_accuracy improved from 0.52550 to 0.53120, saving model to weights-improvement-36-0.53.hdf5\n","313/313 [==============================] - 2s 6ms/step - loss: 1.2146 - accuracy: 0.5712 - val_loss: 1.3582 - val_accuracy: 0.5312\n","Epoch 37/200\n","311/313 [============================>.] - ETA: 0s - loss: 1.2026 - accuracy: 0.5782\n","Epoch 00037: val_accuracy did not improve from 0.53120\n","313/313 [==============================] - 2s 6ms/step - loss: 1.2017 - accuracy: 0.5784 - val_loss: 1.3702 - val_accuracy: 0.5250\n","Epoch 38/200\n","311/313 [============================>.] - ETA: 0s - loss: 1.1950 - accuracy: 0.5775\n","Epoch 00038: val_accuracy did not improve from 0.53120\n","313/313 [==============================] - 2s 6ms/step - loss: 1.1949 - accuracy: 0.5774 - val_loss: 1.3950 - val_accuracy: 0.5183\n","Epoch 39/200\n","309/313 [============================>.] - ETA: 0s - loss: 1.1791 - accuracy: 0.5856\n","Epoch 00039: val_accuracy did not improve from 0.53120\n","313/313 [==============================] - 2s 6ms/step - loss: 1.1810 - accuracy: 0.5849 - val_loss: 1.3718 - val_accuracy: 0.5188\n","Epoch 40/200\n","313/313 [==============================] - ETA: 0s - loss: 1.1679 - accuracy: 0.5864\n","Epoch 00040: val_accuracy did not improve from 0.53120\n","313/313 [==============================] - 2s 6ms/step - loss: 1.1679 - accuracy: 0.5864 - val_loss: 1.3596 - val_accuracy: 0.5307\n","Epoch 41/200\n","302/313 [===========================>..] - ETA: 0s - loss: 1.1589 - accuracy: 0.5913\n","Epoch 00041: val_accuracy did not improve from 0.53120\n","313/313 [==============================] - 2s 5ms/step - loss: 1.1587 - accuracy: 0.5916 - val_loss: 1.3735 - val_accuracy: 0.5278\n","Epoch 42/200\n","312/313 [============================>.] - ETA: 0s - loss: 1.1483 - accuracy: 0.5949\n","Epoch 00042: val_accuracy improved from 0.53120 to 0.54360, saving model to weights-improvement-42-0.54.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.1482 - accuracy: 0.5949 - val_loss: 1.3330 - val_accuracy: 0.5436\n","Epoch 43/200\n","302/313 [===========================>..] - ETA: 0s - loss: 1.1410 - accuracy: 0.5986\n","Epoch 00043: val_accuracy did not improve from 0.54360\n","313/313 [==============================] - 2s 5ms/step - loss: 1.1422 - accuracy: 0.5985 - val_loss: 1.4876 - val_accuracy: 0.4908\n","Epoch 44/200\n","304/313 [============================>.] - ETA: 0s - loss: 1.1213 - accuracy: 0.6045\n","Epoch 00044: val_accuracy did not improve from 0.54360\n","313/313 [==============================] - 2s 5ms/step - loss: 1.1234 - accuracy: 0.6035 - val_loss: 1.3633 - val_accuracy: 0.5324\n","Epoch 45/200\n","303/313 [============================>.] - ETA: 0s - loss: 1.1132 - accuracy: 0.6106\n","Epoch 00045: val_accuracy did not improve from 0.54360\n","313/313 [==============================] - 2s 5ms/step - loss: 1.1131 - accuracy: 0.6105 - val_loss: 1.3455 - val_accuracy: 0.5366\n","Epoch 46/200\n","307/313 [============================>.] - ETA: 0s - loss: 1.1071 - accuracy: 0.6096\n","Epoch 00046: val_accuracy improved from 0.54360 to 0.54650, saving model to weights-improvement-46-0.55.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.1060 - accuracy: 0.6102 - val_loss: 1.3250 - val_accuracy: 0.5465\n","Epoch 47/200\n","307/313 [============================>.] - ETA: 0s - loss: 1.0898 - accuracy: 0.6180\n","Epoch 00047: val_accuracy did not improve from 0.54650\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0910 - accuracy: 0.6179 - val_loss: 1.3620 - val_accuracy: 0.5357\n","Epoch 48/200\n","312/313 [============================>.] - ETA: 0s - loss: 1.0770 - accuracy: 0.6187\n","Epoch 00048: val_accuracy did not improve from 0.54650\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0770 - accuracy: 0.6187 - val_loss: 1.3718 - val_accuracy: 0.5402\n","Epoch 49/200\n","306/313 [============================>.] - ETA: 0s - loss: 1.0746 - accuracy: 0.6225\n","Epoch 00049: val_accuracy did not improve from 0.54650\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0760 - accuracy: 0.6219 - val_loss: 1.3722 - val_accuracy: 0.5378\n","Epoch 50/200\n","309/313 [============================>.] - ETA: 0s - loss: 1.0607 - accuracy: 0.6258\n","Epoch 00050: val_accuracy did not improve from 0.54650\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0612 - accuracy: 0.6258 - val_loss: 1.3561 - val_accuracy: 0.5393\n","Epoch 51/200\n","302/313 [===========================>..] - ETA: 0s - loss: 1.0484 - accuracy: 0.6294\n","Epoch 00051: val_accuracy did not improve from 0.54650\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0502 - accuracy: 0.6290 - val_loss: 1.3650 - val_accuracy: 0.5365\n","Epoch 52/200\n","304/313 [============================>.] - ETA: 0s - loss: 1.0384 - accuracy: 0.6365\n","Epoch 00052: val_accuracy did not improve from 0.54650\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0390 - accuracy: 0.6361 - val_loss: 1.3809 - val_accuracy: 0.5386\n","Epoch 53/200\n","313/313 [==============================] - ETA: 0s - loss: 1.0343 - accuracy: 0.6371\n","Epoch 00053: val_accuracy did not improve from 0.54650\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0343 - accuracy: 0.6371 - val_loss: 1.3939 - val_accuracy: 0.5382\n","Epoch 54/200\n","305/313 [============================>.] - ETA: 0s - loss: 1.0182 - accuracy: 0.6394\n","Epoch 00054: val_accuracy did not improve from 0.54650\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0186 - accuracy: 0.6395 - val_loss: 1.3862 - val_accuracy: 0.5343\n","Epoch 55/200\n","311/313 [============================>.] - ETA: 0s - loss: 1.0148 - accuracy: 0.6414\n","Epoch 00055: val_accuracy improved from 0.54650 to 0.54870, saving model to weights-improvement-55-0.55.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0149 - accuracy: 0.6414 - val_loss: 1.3580 - val_accuracy: 0.5487\n","Epoch 56/200\n","304/313 [============================>.] - ETA: 0s - loss: 1.0039 - accuracy: 0.6450\n","Epoch 00056: val_accuracy did not improve from 0.54870\n","313/313 [==============================] - 2s 5ms/step - loss: 1.0043 - accuracy: 0.6451 - val_loss: 1.3666 - val_accuracy: 0.5441\n","Epoch 57/200\n","311/313 [============================>.] - ETA: 0s - loss: 0.9945 - accuracy: 0.6512\n","Epoch 00057: val_accuracy did not improve from 0.54870\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9951 - accuracy: 0.6508 - val_loss: 1.4246 - val_accuracy: 0.5271\n","Epoch 58/200\n","313/313 [==============================] - ETA: 0s - loss: 0.9848 - accuracy: 0.6521\n","Epoch 00058: val_accuracy did not improve from 0.54870\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9848 - accuracy: 0.6521 - val_loss: 1.3567 - val_accuracy: 0.5410\n","Epoch 59/200\n","305/313 [============================>.] - ETA: 0s - loss: 0.9731 - accuracy: 0.6567\n","Epoch 00059: val_accuracy did not improve from 0.54870\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9738 - accuracy: 0.6564 - val_loss: 1.3530 - val_accuracy: 0.5468\n","Epoch 60/200\n","307/313 [============================>.] - ETA: 0s - loss: 0.9621 - accuracy: 0.6609\n","Epoch 00060: val_accuracy did not improve from 0.54870\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9629 - accuracy: 0.6607 - val_loss: 1.4356 - val_accuracy: 0.5289\n","Epoch 61/200\n","305/313 [============================>.] - ETA: 0s - loss: 0.9560 - accuracy: 0.6631\n","Epoch 00061: val_accuracy did not improve from 0.54870\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9552 - accuracy: 0.6636 - val_loss: 1.4172 - val_accuracy: 0.5274\n","Epoch 62/200\n","302/313 [===========================>..] - ETA: 0s - loss: 0.9489 - accuracy: 0.6651\n","Epoch 00062: val_accuracy did not improve from 0.54870\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9494 - accuracy: 0.6651 - val_loss: 1.3951 - val_accuracy: 0.5443\n","Epoch 63/200\n","303/313 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.6711\n","Epoch 00063: val_accuracy did not improve from 0.54870\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9354 - accuracy: 0.6704 - val_loss: 1.3616 - val_accuracy: 0.5425\n","Epoch 64/200\n","306/313 [============================>.] - ETA: 0s - loss: 0.9291 - accuracy: 0.6736\n","Epoch 00064: val_accuracy improved from 0.54870 to 0.55590, saving model to weights-improvement-64-0.56.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9301 - accuracy: 0.6729 - val_loss: 1.3416 - val_accuracy: 0.5559\n","Epoch 65/200\n","311/313 [============================>.] - ETA: 0s - loss: 0.9204 - accuracy: 0.6755\n","Epoch 00065: val_accuracy did not improve from 0.55590\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9204 - accuracy: 0.6755 - val_loss: 1.3978 - val_accuracy: 0.5416\n","Epoch 66/200\n","307/313 [============================>.] - ETA: 0s - loss: 0.9157 - accuracy: 0.6798\n","Epoch 00066: val_accuracy did not improve from 0.55590\n","313/313 [==============================] - 2s 5ms/step - loss: 0.9145 - accuracy: 0.6802 - val_loss: 1.5057 - val_accuracy: 0.5296\n","Epoch 67/200\n","312/313 [============================>.] - ETA: 0s - loss: 0.8985 - accuracy: 0.6824\n","Epoch 00067: val_accuracy did not improve from 0.55590\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8987 - accuracy: 0.6824 - val_loss: 1.4479 - val_accuracy: 0.5339\n","Epoch 68/200\n","311/313 [============================>.] - ETA: 0s - loss: 0.8910 - accuracy: 0.6867\n","Epoch 00068: val_accuracy did not improve from 0.55590\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8911 - accuracy: 0.6865 - val_loss: 1.3801 - val_accuracy: 0.5520\n","Epoch 69/200\n","305/313 [============================>.] - ETA: 0s - loss: 0.8880 - accuracy: 0.6881\n","Epoch 00069: val_accuracy did not improve from 0.55590\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8866 - accuracy: 0.6886 - val_loss: 1.4505 - val_accuracy: 0.5407\n","Epoch 70/200\n","305/313 [============================>.] - ETA: 0s - loss: 0.8774 - accuracy: 0.6925\n","Epoch 00070: val_accuracy improved from 0.55590 to 0.55610, saving model to weights-improvement-70-0.56.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8764 - accuracy: 0.6931 - val_loss: 1.3692 - val_accuracy: 0.5561\n","Epoch 71/200\n","310/313 [============================>.] - ETA: 0s - loss: 0.8667 - accuracy: 0.6957\n","Epoch 00071: val_accuracy did not improve from 0.55610\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8671 - accuracy: 0.6957 - val_loss: 1.4568 - val_accuracy: 0.5315\n","Epoch 72/200\n","309/313 [============================>.] - ETA: 0s - loss: 0.8566 - accuracy: 0.6974\n","Epoch 00072: val_accuracy did not improve from 0.55610\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8571 - accuracy: 0.6973 - val_loss: 1.4674 - val_accuracy: 0.5388\n","Epoch 73/200\n","313/313 [==============================] - ETA: 0s - loss: 0.8539 - accuracy: 0.6968\n","Epoch 00073: val_accuracy did not improve from 0.55610\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8539 - accuracy: 0.6968 - val_loss: 1.4510 - val_accuracy: 0.5441\n","Epoch 74/200\n","313/313 [==============================] - ETA: 0s - loss: 0.8404 - accuracy: 0.7034\n","Epoch 00074: val_accuracy did not improve from 0.55610\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8404 - accuracy: 0.7034 - val_loss: 1.3721 - val_accuracy: 0.5542\n","Epoch 75/200\n","303/313 [============================>.] - ETA: 0s - loss: 0.8351 - accuracy: 0.7061\n","Epoch 00075: val_accuracy did not improve from 0.55610\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8351 - accuracy: 0.7060 - val_loss: 1.4476 - val_accuracy: 0.5471\n","Epoch 76/200\n","303/313 [============================>.] - ETA: 0s - loss: 0.8227 - accuracy: 0.7120\n","Epoch 00076: val_accuracy did not improve from 0.55610\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8232 - accuracy: 0.7118 - val_loss: 1.4749 - val_accuracy: 0.5437\n","Epoch 77/200\n","310/313 [============================>.] - ETA: 0s - loss: 0.8162 - accuracy: 0.7125\n","Epoch 00077: val_accuracy did not improve from 0.55610\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8164 - accuracy: 0.7127 - val_loss: 1.4190 - val_accuracy: 0.5441\n","Epoch 78/200\n","311/313 [============================>.] - ETA: 0s - loss: 0.8136 - accuracy: 0.7140\n","Epoch 00078: val_accuracy improved from 0.55610 to 0.55670, saving model to weights-improvement-78-0.56.hdf5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8142 - accuracy: 0.7139 - val_loss: 1.4170 - val_accuracy: 0.5567\n","Epoch 79/200\n","313/313 [==============================] - ETA: 0s - loss: 0.8021 - accuracy: 0.7166\n","Epoch 00079: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.8021 - accuracy: 0.7166 - val_loss: 1.4234 - val_accuracy: 0.5446\n","Epoch 80/200\n","302/313 [===========================>..] - ETA: 0s - loss: 0.7914 - accuracy: 0.7219\n","Epoch 00080: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7926 - accuracy: 0.7214 - val_loss: 1.4208 - val_accuracy: 0.5469\n","Epoch 81/200\n","311/313 [============================>.] - ETA: 0s - loss: 0.7922 - accuracy: 0.7217\n","Epoch 00081: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7919 - accuracy: 0.7219 - val_loss: 1.4785 - val_accuracy: 0.5390\n","Epoch 82/200\n","313/313 [==============================] - ETA: 0s - loss: 0.7812 - accuracy: 0.7247\n","Epoch 00082: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7812 - accuracy: 0.7247 - val_loss: 1.5157 - val_accuracy: 0.5395\n","Epoch 83/200\n","303/313 [============================>.] - ETA: 0s - loss: 0.7746 - accuracy: 0.7295\n","Epoch 00083: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7749 - accuracy: 0.7291 - val_loss: 1.4980 - val_accuracy: 0.5498\n","Epoch 84/200\n","302/313 [===========================>..] - ETA: 0s - loss: 0.7669 - accuracy: 0.7334\n","Epoch 00084: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7674 - accuracy: 0.7333 - val_loss: 1.4656 - val_accuracy: 0.5499\n","Epoch 85/200\n","313/313 [==============================] - ETA: 0s - loss: 0.7593 - accuracy: 0.7330\n","Epoch 00085: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7593 - accuracy: 0.7330 - val_loss: 1.5822 - val_accuracy: 0.5430\n","Epoch 86/200\n","311/313 [============================>.] - ETA: 0s - loss: 0.7479 - accuracy: 0.7384\n","Epoch 00086: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7476 - accuracy: 0.7386 - val_loss: 1.4812 - val_accuracy: 0.5536\n","Epoch 87/200\n","306/313 [============================>.] - ETA: 0s - loss: 0.7462 - accuracy: 0.7386\n","Epoch 00087: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7485 - accuracy: 0.7380 - val_loss: 1.4210 - val_accuracy: 0.5538\n","Epoch 88/200\n","312/313 [============================>.] - ETA: 0s - loss: 0.7338 - accuracy: 0.7435\n","Epoch 00088: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7338 - accuracy: 0.7435 - val_loss: 1.5317 - val_accuracy: 0.5522\n","Epoch 89/200\n","311/313 [============================>.] - ETA: 0s - loss: 0.7300 - accuracy: 0.7438\n","Epoch 00089: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7302 - accuracy: 0.7435 - val_loss: 1.5524 - val_accuracy: 0.5438\n","Epoch 90/200\n","309/313 [============================>.] - ETA: 0s - loss: 0.7251 - accuracy: 0.7463\n","Epoch 00090: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7251 - accuracy: 0.7465 - val_loss: 1.5742 - val_accuracy: 0.5378\n","Epoch 91/200\n","311/313 [============================>.] - ETA: 0s - loss: 0.7206 - accuracy: 0.7471\n","Epoch 00091: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.7202 - accuracy: 0.7474 - val_loss: 1.5804 - val_accuracy: 0.5348\n","Epoch 92/200\n","310/313 [============================>.] - ETA: 0s - loss: 0.7134 - accuracy: 0.7503\n","Epoch 00092: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 6ms/step - loss: 0.7135 - accuracy: 0.7504 - val_loss: 1.5002 - val_accuracy: 0.5456\n","Epoch 93/200\n","313/313 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.7556\n","Epoch 00093: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 6ms/step - loss: 0.7016 - accuracy: 0.7556 - val_loss: 1.5099 - val_accuracy: 0.5520\n","Epoch 94/200\n","307/313 [============================>.] - ETA: 0s - loss: 0.6918 - accuracy: 0.7558\n","Epoch 00094: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 6ms/step - loss: 0.6925 - accuracy: 0.7556 - val_loss: 1.4970 - val_accuracy: 0.5510\n","Epoch 95/200\n","305/313 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.7570\n","Epoch 00095: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.6909 - accuracy: 0.7577 - val_loss: 1.5722 - val_accuracy: 0.5386\n","Epoch 96/200\n","309/313 [============================>.] - ETA: 0s - loss: 0.6858 - accuracy: 0.7610\n","Epoch 00096: val_accuracy did not improve from 0.55670\n","313/313 [==============================] - 2s 5ms/step - loss: 0.6856 - accuracy: 0.7612 - val_loss: 1.5970 - val_accuracy: 0.5302\n","\n","Test accuracy: 53.2%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4fjDPjIhiGGc"},"source":["from tensorflow import keras\n","loaded_cifar10_mlp = keras.models.load_model('mlp-cifar10-78-0.56.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PflZhko0m5X3"},"source":["%rm -f mlp-cifar10*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DraGqgmkgva","executionInfo":{"status":"ok","timestamp":1602228336740,"user_tz":240,"elapsed":1208,"user":{"displayName":"Jazon Samillano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh38FD5jYw0f-Aq4w9GYw6VLsoIdOlo8btjIQwQ=s64","userId":"00135806175043031109"}},"outputId":"c5e09768-7647-47bb-f3e4-10ebb8322e85","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["_, acc = loaded_cifar10_mlp.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n","print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Test accuracy: 55.2%\n"],"name":"stdout"}]}]}